[[uses]]
= 用例

以下是 Apache Kafka&reg; 的一些常见用例的描述。有关其中一些设计到领域的概述，请参考此 https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying/[博客]

[[kafka-uses-messaging]]
== Messaging

Kafka 可以作为传统的消息代理的替代。使用消息代理的原因有很多种（将数据的处理和生产解耦，缓冲未处理的消息等）。与大多数的消息系统相比，Kafka 具有更好的吞吐量，内置分区，副本和容错能力，这使其成为大规模应用程序消息处理的良好解决方案。根据我们的
经验，通常消息传递使用的吞吐量相对较低，但也有可能需要端到端的低延时，Kafka 提供强大的持久性来满足这一要求

在这个领域， Kafka 可与传统的消息系统（如 http://activemq.apache.org[ActiveMQ] 或 https://www.rabbitmq.com[RabbitMQ]） 相媲美。

[[kafka-uses-website]]
== 网站活动跟踪

Kafka 最初的用例就是跟踪用户活动，将用户活动跟踪管道重建为一组实时发布-订阅源。这意味着站点活动（页面浏览，搜索或用户采取的其他操作）将发布到中心主题，每个活动类型一个主题。这些订阅源提供一系列用例，包括实时处理，实时监控以及加载到 Hadoop 或离线数据
仓库系统以进行离线处理和报告。

活动跟踪的量通常都非常大，因为每个用户浏览网页时都会生成许多活动消息。

[[kafka-uses-metrics]]
== 监控

Kafka 通常用于监控数据。这涉及到从分布式应用程序中汇总数据，然后生成可操作的集中数据源

[[kafka-uses-logs]]
== 日志聚合

许多人使用 Kafka 作为日志聚合解决方案的替代品。日志聚合通常是从服务器收集物理日志文件，并将它们放在一个中心的位置（可能是文件服务器或 HDFS）进行处理。Kafka 从这些日志文件中提取信息，并将其抽象为一个更加清晰的消息流。这样可以实现更低的延时处理和更容易支持
多个数据源以及分布式数据消费。与 `Scribe` 和 `Flume` 等以日志为中心的系统相比，Kafka 提供了同样出色的性能，由于副本而提供更强的耐用性和更低的延时。

[[kafka-uses-streamprocessing]]
== 流处理

许多 Kafka 的用户通过管道来处理数据，从 Kafka 的主题中消费原始数据，然后聚合，修饰或通过其他方式转换为新的主题，以供进一步消费或处理。例如，一个推荐新闻文章的数据处理管道可能会从 RSS 订阅源中抓取文章内容并将其发布到 "articles" 主题，然后对
这些内容进行标准化或者删除重复的内容，将处理完的内容发布到新的主题中，最后，将这些内容推荐给用户。这种管道基于各个主题创建实时数据流图。从 0.10.0.0 开始，Apache Kafka 提供了一个 {kafka-docs}/documentation/streams[Kafka Streams]，它是轻量级的但功能强大的流处理库，可以使用 Kafka Streams
开执行上述的数据处理。除了 Kafka Streams，替代的开源流处理工具还有 https://storm.apache.org/[Apache Storm] 和 http://samza.apache.org/[Apache Samza]

[[kafka-uses-eventsourcing]]
== 采集日志

http://martinfowler.com/eaaDev/EventSourcing.html[Event sourcing] 是一种应用程序设计风格，按时间来记录状态的更改。Kafka 可以存储非常多的日志数据，为基于 Event sourcing 的应用程序提供强有力的支持。

[[kafka-uses-commitlog]]
== 提交日志

Kafka 可以从外部为分布式系统提供日志提交功能。该日志有助于在节点之间进行复制，并充当节点故障恢复其数据的重新同步机制。Kafka 中的日志 <<kafka-compaction,压缩>> 功能有助于支持这种用法。这中做法类似于 https://bookkeeper.apache.org/[Apache BookKeeper] 项目。