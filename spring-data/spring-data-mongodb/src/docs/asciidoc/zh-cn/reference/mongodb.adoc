[[mongo.core]]
= MongoDB 支持

MongoDB 支持包含许多功能:

* Spring 支持通过基于 Java 的 `@Configuration` 类和 XML 命名空间来配置 Mongo driver 实例和副本集.
* `MongoTemplate` 模板工具类，执行常见的 Mongo 操作。包括 documents 和 POJOs 之间的映射.
* 将异常转换为 Spring 的数据访问异常层次结构。.
* 与 Spring 的转换服务集成丰富的对象映射.
* 基于注解的映射元数据，可扩展以支持其他元数据格式。.
* 持久化和映射生命周期事件。.
* 基于 Java 的查询（Query） , 构造条件（Criteria）, 和 更新（Update） DSLs.
* Repository 接口的自动实现，包括对自定义 finder 方法的支持。.
* QueryDSL 集成以支持类型安全的查询。.
* 对 JPA 实体的跨存储持久化支持，该JPA实体的字段可以通过 MongoDB 透明地持久化和检索（已弃用 - 无需替换即可删除）.
* GeoSpatial 集成.

对于大多数任务，您应该使用 `MongoTemplate` 或 Repository 支持, 它们都具有丰富的映射功能. `MongoTemplate` 是寻找访问功能的地方，比如递增计数器或特别CRUD操作. `MongoTemplate` 还提供回调方法，这样您就可以很容易地获得底层 API artifacts, 例如 `com.mongodb.client.MongoDatabase`, 直接与 MongoDB 通信.在各种 API 构件上使用命名约定的目标是将这些约定复制到基础的 MongoDB Java 驱动程序中，这样您就可以轻松地将现有知识映射到 Spring API 上.

[[mongodb-getting-started]]
== 入门

在 https://spring.io/tools/sts[STS] 中创建一个基于 Spring 的项目，是一种简单的方法来建立一个工作环境.

首先，需要设置一个正在运行的 MongoDB 服务器。关于如何启动 MongoDB 实例，请参考 https://docs.mongodb.org/manual/core/introduction/[MongoDB 快速入门指南]。安装完成后，启动 MongoDB 通常需要运行以下命令: `${MONGO_HOME}/bin/mongod`

在 STS 中创建一个 Spring 工程:

. Go to File -> New -> Spring Template Project -> Simple Spring Utility Project, 并在提示时按 Yes. 然后输入一个项目名和包名, 例如 `org.spring.mongodb.example`.
. 将一下内容添加到 pom.xml 文件的 `dependencies` 元素中:
+
[source,xml,subs="+attributes"]
----
<dependencies>

  <!-- other dependency elements omitted -->

  <dependency>
    <groupId>org.springframework.data</groupId>
    <artifactId>spring-data-mongodb</artifactId>
    <version>{version}</version>
  </dependency>

</dependencies>
----
. 将 pom.xml 中的 Spring 版本切换为
+
[source,xml,subs="+attributes"]
----
<spring.framework.version>{springVersion}</spring.framework.version>
----
. 将 Spring Milestone repository 存储库的以下位置添加到您的 `pom.xml` ，与 `<dependencies/>` 元素同级:
+
[source,xml]
----
<repositories>
  <repository>
    <id>spring-milestone</id>
    <name>Spring Maven MILESTONE Repository</name>
    <url>https://repo.spring.io/libs-milestone</url>
  </repository>
</repositories>
----

这个库也可以在 https://repo.spring.io/milestone/org/springframework/data/[这里浏览] 。
The repository is also .

您可能还希望将日志级别设置为 `DEBUG`，以查看一些其他信息。编辑 `log4j.properties` 文件:

[source]
----
log4j.category.org.springframework.data.mongodb=DEBUG
log4j.appender.stdout.layout.ConversionPattern=%d{ABSOLUTE} %5p %40.40c:%4L - %m%n
----

然后，创建一个 `Person` 实体类:

[source,java]
----
package org.spring.mongodb.example;

public class Person {

  private String id;
  private String name;
  private int age;

  public Person(String name, int age) {
    this.name = name;
    this.age = age;
  }

  public String getId() {
    return id;
  }
  public String getName() {
    return name;
  }
  public int getAge() {
    return age;
  }

  @Override
  public String toString() {
    return "Person [id=" + id + ", name=" + name + ", age=" + age + "]";
  }
}
----

你还需要一个主应用程序来运行:

[source,java]
----
package org.spring.mongodb.example;

import static org.springframework.data.mongodb.core.query.Criteria.where;

import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.springframework.data.mongodb.core.MongoOperations;
import org.springframework.data.mongodb.core.MongoTemplate;
import org.springframework.data.mongodb.core.query.Query;

import com.mongodb.client.MongoClients;

public class MongoApp {

  private static final Log log = LogFactory.getLog(MongoApp.class);

  public static void main(String[] args) throws Exception {

    MongoOperations mongoOps = new MongoTemplate(MongoClients.create(), "database");
    mongoOps.insert(new Person("Joe", 34));

    log.info(mongoOps.findOne(new Query(where("name").is("Joe")), Person.class));

    mongoOps.dropCollection("person");
  }
}
----

运行主程序时，上面的示例输出如下:

[source]
----
10:01:32,062 DEBUG apping.MongoPersistentEntityIndexCreator:  80 - Analyzing class class org.spring.example.Person for index information.
10:01:32,265 DEBUG ramework.data.mongodb.core.MongoTemplate: 631 - insert Document containing fields: [_class, age, name] in collection: Person
10:01:32,765 DEBUG ramework.data.mongodb.core.MongoTemplate:1243 - findOne using query: { "name" : "Joe"} in db.collection: database.Person
10:01:32,953  INFO      org.spring.mongodb.example.MongoApp:  25 - Person [id=4ddbba3c0be56b7e1b210166, name=Joe, age=34]
10:01:32,984 DEBUG ramework.data.mongodb.core.MongoTemplate: 375 - Dropped collection [database.person]
----

即使在这个简单的例子中，也有一些事情需要注意:

* 通过使用标准的 `com.mongodb.client.MongoClient` 对象和要使用的数据库名称，你可以实例化 Spring Mongo 的 <<mongo-template,`MongoTemplate`>>.
* 映射使用标准的 POJO 对象，而不需要任何额外的元数据(尽管您可以选择提供该信息。See <<mapping-chapter,here>>)。
* 约定用于处理 `id` 字段，在存储在数据库中时将其转换为一个 `ObjectId`
* 映射约定可以使用字段访问。注意，`Person` 类只有getter。
* 如果构造函数参数名称与存储文档的字段名称匹配，则使用它们实例化对象

[[mongo.examples-repo]]
== Repository 示例

这里有一个 GitHub 库，里面有 https://github.com/spring-projects/spring-data-examples[几个例子] ，您可以下载下来体验研究一下库的使用.

[[mongodb-connectors]]
== 使用 Spring 连接 MongoDB

第一步是使用 IoC 容器创建一个 `com.mongodb.client.MongoClient`  对象。有两种主要方法可以做到这一点，一种是使用基于 java 的 bean 元数据，另一种是使用基于 xml 的 bean 元数据。下面将讨论这两种情况。

NOTE: 对于那些不熟悉如何使用基于 Java Bean 元数据而不是基于 xml 元数据配置 Spring 容器的人，请参阅参考文档中的 https://docs.spring.io/spring/docs/{springVersion}/spring-framework-reference/core.html#beans-java-instantiating-container[高级介绍] 以及此处的 https://docs.spring.io/spring/docs/3.2.x/spring-framework-reference/html/new-in-3.0.html#new-java-configuration[详细文档] 。

[[mongo.mongo-java-config]]
=== 使用基于 Java 的方式注册一个 Mongo 实例

下面的例子展示了一个使用基于 Java Bean 元数据注册 `com.mongodb.client.MongoClient` 实例的例子:

.使用基于 Java Bean 元数据注册 `com.mongodb.client.MongoClient` 对象
====
[source,java]
----
@Configuration
public class AppConfig {

  /*
   * Use the standard Mongo driver API to create a com.mongodb.client.MongoClient instance.
   */
   public @Bean MongoClient mongoClient() {
       return MongoClients.create("mongodb://localhost:27017");
   }
}
----
====

这种方式允许您使用标准的 `com.mongodb.client.MongoClient` 实例，而容器使用 Spring 的 `MongoClientFactoryBean`。与直接实例化 `com.mongodb.client.MongoClient` 实例相比，FactoryBean 还有一个额外的优势，它为容器提供了一个 `ExceptionTranslator` 实现，可以将 MongoDB 的异常转换为 Spring 的 `DataAccessException` 层次结构中的异常，用于用 `@Repository` 注解的数据访问类。这个层次结构和 `@Repository` 的使用在 https://docs.spring.io/spring/docs/{springVersion}/spring-framework-reference/data-access.html[Spring 的 DAO 支持特性]中有描述。

下面的例子展示了一个基于 java bean元数据的例子，它支持 `@Repository` 注解类的异常转换:

.通过 `MongoClientFactoryBean` 注册一个 `com.mongodb.client.MongoClient` 对象，并启用 Spring 的异常转换支持。
====
[source,java]
----
@Configuration
public class AppConfig {

    /*
     * Factory bean that creates the com.mongodb.client.MongoClient instance
     */
     public @Bean MongoClientFactoryBean mongo() {
          MongoClientFactoryBean mongo = new MongoClientFactoryBean();
          mongo.setHost("localhost");
          return mongo;
     }
}
----
====

`com.mongodb.client.MongoClient` 对象是由 `MongoClientFactoryBean` 在 `@Configuration` 注解的类中创建的，要访问 `com.mongodb.client.MongoClient` ，请使用 `private @Autowired Mongo mongo;` 字段。

[[mongo.mongo-xml-config]]
=== 通过基于 XML 元数据配置 Mongo 实例

虽然可以使用 Spring 传统的  `<beans/>`  XML 命名空间向容器注册 `com.mongodb.client.MongoClient` 的实例，但 XML 可能非常冗长。XML 命名空间是配置常用对象(如 Mongo 实例)的更好选择。mongo 名称空间允许您创建一个 mongo 实例服务器位置、副本集和选项。

要使用 Mongo 命名空间元素，需要引用 Mongo schema，如下所示:

.XML schema to configure MongoDB
====
[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
          xmlns:mongo="http://www.springframework.org/schema/data/mongo"
          xsi:schemaLocation=
          "
          http://www.springframework.org/schema/data/mongo https://www.springframework.org/schema/data/mongo/spring-mongo.xsd
          http://www.springframework.org/schema/beans
          https://www.springframework.org/schema/beans/spring-beans.xsd">

    <!-- Default bean name is 'mongo' -->
    <mongo:mongo-client host="localhost" port="27017"/>

</beans>
----
====

下面的例子展示了使用 `MongoClientSettings` 更高级的配置(注意，这些不是推荐值):

.使用 `MongoClientSettings` 配置 `com.mongodb.client.MongoClient`
====
[source,xml]
----
<beans>

  <mongo:mongo-client host="localhost" port="27017">
    <mongo:client-settings connection-pool-max-connection-life-time="10"
        connection-pool-min-size="10"
		connection-pool-max-size="20"
		connection-pool-maintenance-frequency="10"
		connection-pool-maintenance-initial-delay="11"
		connection-pool-max-connection-idle-time="30"
		connection-pool-max-wait-time="15" />
  </mongo:mongo-client>

</beans>
----
====

使用副本集配置如下:

.使用副本集配置 `com.mongodb.client.MongoClient` 对象
====
[source,xml]
----
<mongo:mongo-client id="replicaSetMongo" replica-set="rs0">
    <mongo:client-settings cluster-hosts="127.0.0.1:27017,localhost:27018" />
</mongo:mongo-client>
----
====

[[mongo.mongo-db-factory]]
=== MongoDatabaseFactory 接口

虽然 `com.mongodb.client.MongoClient` 是 MongoDB 驱动程序 API 的入口点，但是连接到特定的 MongoDB 数据库实例需要额外的信息，例如数据库名称和可选的用户名和密码。有了这些信息，您就可以获得 `com.mongodb.client.MongoDatabase` 对象并访问特定 `MongoDB` 数据库实例的所有功能。Spring 提供了 `org.springframework.data.mongodb.core.MongoDatabaseFactory` 接口，如下清示，用来引导连接到数据库:

[source,java]
----
public interface MongoDatabaseFactory {

  MongoDatabase getDatabase() throws DataAccessException;

  MongoDatabase getDatabase(String dbName) throws DataAccessException;
}
----

下面的部分将展示如何使用容器和基于 java 或基于 xml 的元数据来配置 `MongoDatabaseFactory` 接口的实例。反过来，你可以使用 `MongoDatabaseFactory` 实例来配置 `MongoTemplate`。

不需要使用 IoC 容器来创建一个 `MongoTemplate` 实例，你可以在 Java 代码中直接使用它们，如下所示:

[source,java]
----
public class MongoApp {

  private static final Log log = LogFactory.getLog(MongoApp.class);

  public static void main(String[] args) throws Exception {

    MongoOperations mongoOps = new MongoTemplate(new SimpleMongoClientDatabaseFactory(MongoClients.create(), "database"));

    mongoOps.insert(new Person("Joe", 34));

    log.info(mongoOps.findOne(new Query(where("name").is("Joe")), Person.class));

    mongoOps.dropCollection("person");
  }
}
----

粗体显示的代码强调了 `SimpleMongoClientDbFactory` 的使用，这是与 <<mongodb-getting-started,入门章节>> 中显示的唯一区别。

NOTE: 当选择 `com.mongodb.client.MongoClient` 作为入口点时，使用 `SimpleMongoClientDbFactory`。

[[mongo.mongo-db-factory-java]]
=== 通过基于 Java 的方式注册一个 `MongoDatabaseFactory` 实例

要向容器注册一个 `MongoDatabaseFactory` 实例，需要编写类似于前面代码中突出显示的代码。下面展示了一个简单的例子

[source,java]
----
@Configuration
public class MongoConfiguration {

  public @Bean MongoDatabaseFactory mongoDatabaseFactory() {
    return new SimpleMongoClientDatabaseFactory(MongoClients.create(), "database");
  }
}
----

MongoDB 3 连接 DB 时修改了认证模式。因此，用于身份验证的一些配置选项不再有效。你应该使用特定的 `MongoClient` 选项，通过 `MongoCredential` 设置凭据来提供认证数据，如下所示:

[source,java]
----
@Configuration
public class ApplicationContextEventTestsAppConfig extends AbstractMongoClientConfiguration {

  @Override
  public String getDatabaseName() {
    return "database";
  }

  @Override
  protected void configureClientSettings(Builder builder) {

  	builder
  	    .credential(MongoCredential.createCredential("name", "db", "pwd".toCharArray()))
  	    .applyToClusterSettings(settings  -> {
  	    	settings.hosts(singletonList(new ServerAddress("127.0.0.1", 27017)));
  	    });
  }
}
----

为了在基于 xml 的配置中使用身份验证，请在 `<mongo-client>` 元素上使用 `credential` 属性。

NOTE: 在基于xml的配置中使用的用户名和密码凭证必须在包含保留字符时进行 URL 编码, 例如 `:`, `%`, `@`, or `,`.
下面的例子显示了编码后的凭证:
`m0ng0@dmin:mo_res:bw6},Qsdxx@admin@database` -> `m0ng0%40dmin:mo_res%3Abw6%7D%2CQsdxx%40admin@database`
请查看 https://tools.ietf.org/html/rfc3986#section-2.2[section 2.2 of RFC 3986] 获取更多信息.

[[mongo.mongo-db-factory-xml]]
=== 通过基于 XML 的方式注册一个 `MongoDatabaseFactory` 实例

与使用 `<beans/>` 命名空间相比，`mongo` 命名空间提供了一种创建 `SimpleMongoClientDbFactory` 的便捷方式，如下所示:

[source,xml]
----
<mongo:db-factory dbname="database">
----

如果需要在 `com.mongodb.client.MongoClient` 实例上配置用于创建 SimpleMongoClientDbFactory 的其他选项，则可以使用 `mongo-ref` 属性引用现有 bean，如下例所示。为了展示另一个常见的使用模式，下面的代码展示了属性占位符的使用，它可以让你参数化配置和创建一个 `MongoTemplate`:

[source,xml]
----
<context:property-placeholder location="classpath:/com/myapp/mongodb/config/mongo.properties"/>

<mongo:mongo-client host="${mongo.host}" port="${mongo.port}">
  <mongo:client-settings connection-pool-max-connection-life-time="${mongo.pool-max-life-time}"
    connection-pool-min-size="${mongo.pool-min-size}"
    connection-pool-max-size="${mongo.pool-max-size}"
	connection-pool-maintenance-frequency="10"
	connection-pool-maintenance-initial-delay="11"
	connection-pool-max-connection-idle-time="30"
	connection-pool-max-wait-time="15" />
</mongo:mongo-client>

<mongo:db-factory dbname="database" mongo-ref="mongoClient"/>

<bean id="anotherMongoTemplate" class="org.springframework.data.mongodb.core.MongoTemplate">
  <constructor-arg name="mongoDbFactory" ref="mongoDbFactory"/>
</bean>
----

[[mongo-template]]
== 介绍 `MongoTemplate`

`MongoTemplate` 类位于 `org.springframework.data.mongodb.core` 包中，是 Spring MongoDB 支持的核心类，为与数据库交互提供了丰富的特性。该模板提供了创建、更新、删除和查询 MongoDB 文档的 documents 操作，并提供了 domain 对象和 MongoDB  documents 之间的映射关系。

NOTE: 一旦配置, `MongoTemplate` 是线程安全的，可以在多个实例中重用

MongoDB documents 和 domain 类之间的映射是通过委托给 `MongoConverter` 接口的一个实现来完成的。Spring 提供了 `MappingMongoConverter`，但是您也可以编写自己的转换器。有关更多详细信息，请参阅 "`<<mongo.custom-converters>>`"。

`MongoTemplate` 类实现了 `MongoOperations` 接口。在尽可能的情况下，MongoDB 操作的方法都以 MongoDB driver Collection 对象中可用的方法命名，以使已经使用过该驱动 API的 MongoDB 开发人员熟悉该 API。例如，你可以找到 `find`、`findAndModify`、`findAndReplace`、`findOne`、`insert`、`remove`、`save`、`update` 和 `updateMulti` 等方法。该设计目标是尽可能轻松地在基础 MongoDB 驱动程序和 `MongoOperations` 之间进行转换。这两个 api 的主要区别在于，`MongoOperations` 可以传递 domain 对象，而不是 `Document`。此外，`MongoOperations` 拥有用于查询、标准和更新操作的流式 api，而不是通过填充 `Document` 来指定这些操作的参数。

NOTE: 在 `MongoTemplate` 实例上引用操作的首选方式是通过它的接口 `MongoOperations`。

默认的 `MongoTemplate` 使用的转换器实现是 `MappingMongoConverter`。虽然 `MappingMongoConverter` 可以使用额外的元数据来指定对象到文档的映射，但它也可以通过使用 IDs 和集合名称映射的一些约定来转换不包含额外元数据的对象。这些约定以及映射注解的使用将在 "`<<mapping-chapter>>`"  一章中进行解释

`MongoTemplate` 的另一个核心特性是将 MongoDB Java 驱动程序抛出的异常转换到 Spring 的可移植的数据访问异常层次结构中。有关更多信息，请参阅 "`<<mongo.exception>>`"。

`MongoTemplate` 提供了许多简便的方法来帮助您轻松地执行常见的任务。然而，如果你需要直接访问 MongoDB 驱动程序 API，你可以使用几个 Execute 回调方法之一。执行回调给您一个`com.mongodb.client.MongoCollection` 或 `com.mongodb.client.MongoDatabase` 对象的引用。有关更多信息，请参阅 <<mongo.executioncallback,"`Execution Callbacks`">> 一节。

下一节包含如何在 Spring 容器的上下文中使用 `MongoTemplate` 的示例。

[[mongo-template.instantiating]]
=== 实例化 `MongoTemplate`

你可以使用 Java 来创建和注册一个 MongoTemplate 的实例，如下所示:

====
[source,java]
----
@Configuration
public class AppConfig {

  public @Bean MongoClient mongoClient() {
      return MongoClients.create("mongodb://localhost:27017");
  }

  public @Bean MongoTemplate mongoTemplate() {
      return new MongoTemplate(mongoClient(), "mydatabase");
  }
}
----
====

`MongoTemplate` 有几个重载的构造函数:

* `MongoTemplate(MongoClient mongo, String databaseName)`: 需要 `MongoClient` 对象和要操作的数据库名称
* `MongoTemplate(MongoDatabaseFactory mongoDbFactory)`: 需要 MongoDbFactory 对象， 该对象封装了 `MongoClient` 对象、数据库名称、用户名和密码。
* `MongoTemplate(MongoDatabaseFactory mongoDbFactory, MongoConverter mongoConverter)`: 添加一个 `MongoConverter` 用于映射。

你也可以通过使用 Spring 的 XML <beans/> schema 来配置 `MongoTemplate`，如下所示

[source,xml]
----
<mongo:mongo-client host="localhost" port="27017"/>

<bean id="mongoTemplate" class="org.springframework.data.mongodb.core.MongoTemplate">
  <constructor-arg ref="mongoClient"/>
  <constructor-arg name="databaseName" value="geospatial"/>
</bean>
----

在创建 `MongoTemplate` 时，你可能想要设置的其他可选属性是默认的 `WriteResultCheckingPolicy`、`WriteConcern` 和 `ReadPreference` 属性。

NOTE: 在 `MongoTemplate` 实例上引用操作的首选方式是通过它的接口 `MongoOperations`。

[[mongo-template.writeresultchecking]]
=== `WriteResultChecking` Policy

在开发过程中，如果从 `MongoDB` 操作返回的 `com.mongodb.WriteResult` 包含一个错误，那么记录或抛出一个异常都是很方便的。在开发过程中，常常会忘记这样做，结果应用程序看起来好像成功运行了，而实际上，数据库并没有按照您的期望进行修改。你可以将 `MongoTemplate` 的 `WriteResultChecking` 属性设置为以下值之一: `EXCEPTION` 或 `NONE`，分别抛出一个 `Exception` 或什么都不做。默认值是使用一个 `NONE` 的 `WriteResultChecking` 值。

[[mongo-template.writeconcern]]
=== `WriteConcern`

如果没有通过  `com.mongodb.client.MongoClient` 指定，那么可以设置 `com.mongodb.WriteConcern` 属性，`MongoTemplate` 使用该属性进行写操作。如果没有设置 `WriteConcern` 属性，它默认由 MongoDB 驱动的 DB 或 Collection 设置。

[[mongo-template.writeconcernresolver]]
=== `WriteConcernResolver`

对于更高级的情况，您想要在每个操作的基础上设置不同的 `WriteConcern` 值(用于删除、更新、插入和保存操作)，可以在 `MongoTemplate` 上配置一个名为 `WriteConcernResolver` 的策略接口。因为 `MongoTemplate` 是用来持久化 POJO 的，所以 `WriteConcernResolver` 可以让你创建一个策略来映射一个特定的 POJO 类到一个 `WriteConcern` 值。下面的清单显示了 `WriteConcernResolver` 接口

[source,java]
----
public interface WriteConcernResolver {
  WriteConcern resolve(MongoAction action);
}
----

您可以使用 `MongoAction` 参数来确定 `WriteConcern` 值，或者使用 Template 本身的值作为默认值。`MongoAction` 包含要写入的集合名称、POJO 的 `java.lang.Class`、转换后的 `Document`、操作(`REMOVE`、`UPDATE`、`INSERT`、`INSERT_LIST` 或 `SAVE`)，以及其他一些上下文信息。下面的例子展示了两组获得不同 `WriteConcern` 设置的类

[source]
----
private class MyAppWriteConcernResolver implements WriteConcernResolver {

  public WriteConcern resolve(MongoAction action) {
    if (action.getEntityClass().getSimpleName().contains("Audit")) {
      return WriteConcern.NONE;
    } else if (action.getEntityClass().getSimpleName().contains("Metadata")) {
      return WriteConcern.JOURNAL_SAFE;
    }
    return action.getDefaultWriteConcern();
  }
}
----

[[mongo-template.save-update-remove]]
== 保存, 更新, 和 删除 Documents

`MongoTemplate` 允许您保存、更新和删除 domain 对象，并将这些对象映射到存储在 MongoDB 中的 Documents。

考虑下面的类:

[source,java]
----
public class Person {

  private String id;
  private String name;
  private int age;

  public Person(String name, int age) {
    this.name = name;
    this.age = age;
  }

  public String getId() {
    return id;
  }
  public String getName() {
    return name;
  }
  public int getAge() {
    return age;
  }

  @Override
  public String toString() {
    return "Person [id=" + id + ", name=" + name + ", age=" + age + "]";
  }

}
----

如上的  `Person` 类，你可以保存、更新和删除对象，如下所示:

NOTE: `MongoOperations` 是 `MongoTemplate` 实现的接口。

[source,java]
----
package org.spring.example;

import static org.springframework.data.mongodb.core.query.Criteria.where;
import static org.springframework.data.mongodb.core.query.Update.update;
import static org.springframework.data.mongodb.core.query.Query.query;

import java.util.List;

import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.springframework.data.mongodb.core.MongoOperations;
import org.springframework.data.mongodb.core.MongoTemplate;
import org.springframework.data.mongodb.core.SimpleMongoClientDbFactory;

import com.mongodb.client.MongoClients;

public class MongoApp {

  private static final Log log = LogFactory.getLog(MongoApp.class);

  public static void main(String[] args) {

    MongoOperations mongoOps = new MongoTemplate(new SimpleMongoClientDbFactory(MongoClients.create(), "database"));

    Person p = new Person("Joe", 34);

    // Insert is used to initially store the object into the database.
    mongoOps.insert(p);
    log.info("Insert: " + p);

    // Find
    p = mongoOps.findById(p.getId(), Person.class);
    log.info("Found: " + p);

    // Update
    mongoOps.updateFirst(query(where("name").is("Joe")), update("age", 35), Person.class);
    p = mongoOps.findOne(query(where("name").is("Joe")), Person.class);
    log.info("Updated: " + p);

    // Delete
    mongoOps.remove(p);

    // Check that deletion worked
    List<Person> people =  mongoOps.findAll(Person.class);
    log.info("Number of people = : " + people.size());


    mongoOps.dropCollection(Person.class);
  }
}
----

上面的例子将产生以下日志输出(包括来自 `MongoTemplate` 的调试消息):

[source]
----
DEBUG apping.MongoPersistentEntityIndexCreator:  80 - Analyzing class class org.spring.example.Person for index information.
DEBUG work.data.mongodb.core.MongoTemplate: 632 - insert Document containing fields: [_class, age, name] in collection: person
INFO               org.spring.example.MongoApp:  30 - Insert: Person [id=4ddc6e784ce5b1eba3ceaf5c, name=Joe, age=34]
DEBUG work.data.mongodb.core.MongoTemplate:1246 - findOne using query: { "_id" : { "$oid" : "4ddc6e784ce5b1eba3ceaf5c"}} in db.collection: database.person
INFO               org.spring.example.MongoApp:  34 - Found: Person [id=4ddc6e784ce5b1eba3ceaf5c, name=Joe, age=34]
DEBUG work.data.mongodb.core.MongoTemplate: 778 - calling update using query: { "name" : "Joe"} and update: { "$set" : { "age" : 35}} in collection: person
DEBUG work.data.mongodb.core.MongoTemplate:1246 - findOne using query: { "name" : "Joe"} in db.collection: database.person
INFO               org.spring.example.MongoApp:  39 - Updated: Person [id=4ddc6e784ce5b1eba3ceaf5c, name=Joe, age=35]
DEBUG work.data.mongodb.core.MongoTemplate: 823 - remove using query: { "id" : "4ddc6e784ce5b1eba3ceaf5c"} in collection: person
INFO               org.spring.example.MongoApp:  46 - Number of people = : 0
DEBUG work.data.mongodb.core.MongoTemplate: 376 - Dropped collection [database.person]
----

`MongoConverter` 通过识别(通过约定)Id 属性名，在存储在数据库中的 `String` 和 `ObjectId` 之间进行隐式转换。

NOTE: 前面的例子是为了展示在 `MongoTemplate` 上保存、更新和删除操作的使用，而不是为了展示复杂的映射功能。

上例中使用的查询语法将在  "`<<mongo.query>>`" 一节中进行更详细的解释。

[[mongo-template.id-handling]]
=== `_id` 字段是如何进行映射

MongoDB 要求您为所有 documents 有一个 `_id` 字段。如果你不提供一个，驱动程序会给一个 `ObjectId` 分配一个生成的值。当你使用 `MappingMongoConverter` 时，某些规则控制Java 类的属性如何映射到这个 `_id` 字段:

. 一个 `@Id` (`org.springframework.data.annotation.Id`) 注解的属性或字段映射到 `_id` 字段.
. 没有注解但命名为 `id` 的属性或字段映射到 `id` 映射到 `_id` 字段.

下面概述了在使用 `MappingMongoConverter`(默认的 `MongoTemplate`)时，在映射到 `_id` document 字段的属性上进行的类型转换(如果有的话)。

. 如果可能，您可以在 Java 类中声明一个 `String` 类型的 `id` 属性或字段，Spring 将使用 `Converter<String, ObjectId>` 转换为并存储为 `ObjectId`  ,如果可以转换，将委托给 MongoDB Java driver. 如果不能转换为 `ObjectId`, 那么该值将作为字符串存储在数据库中。
. 在 Java 类中声明为 `BigInteger` 的 `id` 属性或字段，Spring 将使用  `Converter<BigInteger, ObjectId>` 转换为并存储为 `ObjectId`.

如果 Java 类中没有前面几组规则中指定的字段或属性，那么驱动程序将生成一个隐式的 `_id` 文件，但不会映射到 Java 类的属性或字段。

当查询和更新时，`MongoTemplate` 使用了与上述保存文档规则相对应的转换器，这样查询中使用的字段名和类型就可以与 domain 类中的内容相匹配。

有些环境需要自定义方法来映射 `Id` 值，例如存储在 MongoDB 中的数据，该数据不通过 Spring 数据映射。Documents 可以包含可以用作 `ObjectID` 或字符串表示的 `_id` 值。将 Documents 从存储读取回 domain 类型即可。由于隐式的 `ObjectId` 转换，通过文档的 `id` 查询文档可能很麻烦。因此，无法以这种方式检索文档。对于这些情况，`@MongoId` 对实际的 `id` 映射尝试提供了更多的控制。

.`@MongoId` mapping
====
[source,java]
----
public class PlainStringId {
  @MongoId String id; <1>
}

public class PlainObjectId {
  @MongoId ObjectId id; <2>
}

public class StringToObjectId {
  @MongoId(FieldType.OBJECT_ID) String id; <3>
}
----
<1> id 被当作 `String` 处理，无需进一步转换。
<2> id 被视为 `ObjectId`。
<3> 如果给定的 `String` 是一个有效的 `ObjectId` 十六进制，则 id 被视为 `ObjectId`，否则作为 String。对应于 `@Id` 的使用。
====

[[mongo-template.type-mapping]]
=== 类型映射

MongoDB 集合可以包含表示各种类型实例的 documents。如果您存储类的层次结构或具有 `Object` 类型属性的类，此特性将非常有用。在后一种情况下，当检索对象时，必须正确地读入该属性中保存的值。因此，我们需要一种机制来与实际文档一起存储类型信息。

为了实现这一点，`MappingMongoConverter` 使用了一个 `MongoTypeMapper` 抽象，并将 `DefaultMongoTypeMapper` 作为其主要实现。它的默认行为是将完全限定类名存储在文档中的 `_class` 下。类型提示是为顶级文档以及每个值(如果它是复杂类型和声明的属性类型的子类型)编写的。下面的例子(最后是 JSON 表示)展示了映射是如何工作的:

.类型映射
====
[source,java]
----
public class Sample {
  Contact value;
}

public abstract class Contact { … }

public class Person extends Contact { … }

Sample sample = new Sample();
sample.value = new Person();

mongoTemplate.save(sample);

{
  "value" : { "_class" : "com.acme.Person" },
  "_class" : "com.acme.Sample"
}
----
====

Spring Data MongoDB 将类型信息存储为实际根类以及嵌套类型的最后一个字段(因为它很复杂，而且是 `Contact` 的子类型)。因此，如果你现在使用 `mongoTemplate.findAll(Object.class, "sample")`，你可以发现存储的文档是一个 `Sample` 实例。您还可以发现 `value` 属性实际上是一个 `Person`。

==== 自定义类型映射

如果您希望避免将整个 Java 类名编写为类型信息，而更希望使用 key，则可以在实体类上使用 `@TypeAlias` 注解。如果需要进一步定制映射，请查看 `TypeInformationMapper` 接口。该接口的实例可以在 `DefaultMongoTypeMapper` 上配置，而 `DefaultMongoTypeMapper` 又可以在 `MappingMongoConverter` 上配置。下面的例子展示了如何为实体定义类型别名:

.为 Entity 定义一个类型别名
====
[source,java]
----
@TypeAlias("pers")
class Person {

}
----
====

注意，结果 document 包含 `pers` 作为 `_class` Field 中的值。

[WARNING]
====
只有当映射上下文知道实际的类型时，类型别名才有效。所需的实体元数据要么在第一次保存时确定，要么必须通过配置初始实体集提供。默认情况下，配置类扫描 base 包寻找候选包。

[source,java]
----
@Configuration
public class AppConfig extends AbstractMongoClientConfiguration {

  @Override
  protected Set<Class<?>> getInitialEntitySet() {
    return Collections.singleton(Person.class);
  }

  // ...
}
----
====

==== 配置自定义类型映射

下面的例子展示了如何在 `MappingMongoConverter` 中配置一个自定义的 `MongoTypeMapper`:

.使用 Spring Java Config 配置 `MongoTypeMapper`
====
[source,java]
----
class CustomMongoTypeMapper extends DefaultMongoTypeMapper {
  //implement custom type mapping here
}
----


[source,java]
----
@Configuration
class SampleMongoConfiguration extends AbstractMongoClientConfiguration {

  @Override
  protected String getDatabaseName() {
    return "database";
  }

  @Bean
  @Override
  public MappingMongoConverter mappingMongoConverter() throws Exception {
    MappingMongoConverter mmc = super.mappingMongoConverter();
    mmc.setTypeMapper(customTypeMapper());
    return mmc;
  }

  @Bean
  public MongoTypeMapper customTypeMapper() {
    return new CustomMongoTypeMapper();
  }
}
----
====

注意，前面的示例扩展了 `AbstractMongoClientConfiguration` 类，并覆盖了我们配置自定义 `MongoTypeMapper` 的 `MappingMongoConverter` 的 bean 定义。

下面的例子展示了如何使用 XML 配置一个自定义的 `MongoTypeMapper`:

.使用 XML 自定义一个 `MongoTypeMapper`
====
[source,xml]
----
<mongo:mapping-converter type-mapper-ref="customMongoTypeMapper"/>

<bean name="customMongoTypeMapper" class="com.bubu.mongo.CustomMongoTypeMapper"/>
----
====

[[mongo-template.save-insert]]
=== 保存和插入 Documents 的方法

在 `MongoTemplate` 中有几个简便的方法来保存和插入对象。为了对转换过程进行更细粒度的控制，你可以用 `MappingMongoConverter` 注册 Spring 转换器——例如 `Converter<Person, Document>` 和 `Converter<Document, Person>`。

NOTE: 插入操作和保存操作的区别在于，如果对象不存在，则保存操作执行插入操作。

使用保存操作的简单情况是保存 POJO。在本例中，集合名称由类的名称(非完全限定)决定。您还可以使用特定的集合名称调用保存操作。您可以使用映射元数据覆盖用于存储对象的集合。

在插入或保存时，如果没有设置 `Id` 属性，则假设它的值将由数据库自动生成。因此，为了成功地自动生成 `ObjectId`，类中的 `Id` 属性或字段的类型必须是 `String`、`ObjectId` 或 `BigInteger`。

下面的例子展示了如何保存 documents 并获取它的内容:

.使用 `MongoTemplate` 插入和检索文档
====
[source,java]
----
import static org.springframework.data.mongodb.core.query.Criteria.where;
import static org.springframework.data.mongodb.core.query.Criteria.query;
…

Person p = new Person("Bob", 33);
mongoTemplate.insert(p);

Person qp = mongoTemplate.findOne(query(where("age").is(33)), Person.class);
----
====

插入和保存操作如下:

* `void` *save* `(Object objectToSave)`: 将对象保存到默认集合。
* `void` *save* `(Object objectToSave, String collectionName)`: 将对象保存到指定的集合中。

也可以使用类似的插入操作:

* `void` *insert* `(Object objectToSave)`: 将对象插入到默认集合。
* `void` *insert* `(Object objectToSave, String collectionName)`: 将对象插入到特定集合。

[[mongo-template.save-insert.collection]]
==== 我的 Documents 被保存到哪个集合?

有两种方法可以管理用于文档的集合名称。默认集合名是以小写字母开头的类名。因此 `com.test.Person` 类存储在 `person` 集合中。您可以通过使用 `@Document` 注解提供不同的集合名称来自定义这一点。您还可以通过提供您自己的集合名称作为 `MongoTemplate` 方法调用的最后一个参数来覆盖集合名称。

[[mongo-template.save-insert.individual]]
==== 插入或保存单个对象

MongoDB 驱动支持在单个操作中插入一组 documents。`MongoOperations` 接口中的以下方法支持此功能:

* *insert*: 插入对象。如果存在具有相同 `id` 的文档，则会生成错误。
* *insertAll*: 将对象 `Collection` 作为第一个参数。该方法根据前面指定的规则检查每个对象并将其插入到适当的集合中。
* *save*: 保存对象，覆盖具有相同 `id` 的对象。

[[mongo-template.save-insert.batch]]
==== 批量插入数据

MongoDB 驱动支持在一个操作中插入一组 documents。`MongoOperations` 接口中的以下方法支持此功能:

* *insert* methods: 将 `Collection` 作为第一个参数。它们在对数据库的单个批处理写入中插入对象列表。

[[mongodb-template-update]]
=== 在集合中更新 Documents

对于更新，您可以使用 `MongoOperation.updateFirst` 找到的第一个文档。或者您可以使用 `MongoOperation.updateMulti` 更新所有匹配查询的文档。下面的例子显示了所有 `SAVINGS` 账户的更新，其中我们使用  `$inc`  操作符在余额中添加了一次性的 `$50.00` 奖金:

.使用 `MongoTemplate` 更新 documents
====
[source,java]
----
import static org.springframework.data.mongodb.core.query.Criteria.where;
import static org.springframework.data.mongodb.core.query.Query;
import static org.springframework.data.mongodb.core.query.Update;

...

WriteResult wr = mongoTemplate.updateMulti(new Query(where("accounts.accountType").is(Account.Type.SAVINGS)),
  new Update().inc("accounts.$.balance", 50.00), Account.class);
----
====

除了前面讨论的 `Query` 之外，我们还通过使用 `Update` 对象提供更新定义。`Update` 类有匹配 `MongoDB` 可用更新修饰符的方法。

大多数方法返回 `Update` 对象，为 API 提供流式支持。

[[mongodb-template-update.methods]]
==== 更新 Documents 的方法

* *updateFirst*: 将与查询文档条件匹配的第一个文档与更新的文档进行更新。
* *updateMulti*: 更新所有匹配的文档。

WARNING: `updateFirst` 不支持排序。请使用 <<mongo-template.find-and-upsert, findAndModify>> 应用 `Sort`.

[[mongodb-template-update.update]]
==== `Update` 类中的方法

您可以对 `Update` 类使用一点“语法糖”，因为它的方法是链接在一起的。此外，您还可以通过使用 `public static Update update(String key, Object value)` 和使用静态导入启动一个新的 `Update` 实例的创建。

`Update` 包含以下方法:

* `Update` *addToSet* `(String key, Object value)` 使用 `$addToSet` 更新修饰符进行更新
* `Update` *currentDate* `(String key)` 使用 `$currentDate` update 更新修饰符进行更新
* `Update` *currentTimestamp* `(String key)` 使用 带有 `$type` `timestamp` 的 `$currentDate` 更新修饰符进行更新
* `Update` *inc* `(String key, Number inc)` 使用 `$inc` 更新修饰符进行更新
* `Update` *max* `(String key, Object max)` 使用 `$max` 更新修饰符进行更新
* `Update` *min* `(String key, Object min)` 使用 `$min` 更新修饰符进行更新
* `Update` *multiply* `(String key, Number multiplier)` 使用 `$mul` 更新修饰符进行更新
* `Update` *pop* `(String key, Update.Position pos)` 使用 `$pop` 更新修饰符进行更新
* `Update` *pull* `(String key, Object value)` 使用 `$pull` 更新修饰符进行更新
* `Update` *pullAll* `(String key, Object[] values)` 使用 `$pullAll` 更新修饰符进行更新
* `Update` *push* `(String key, Object value)` 使用 `$push` 更新修饰符进行更新
* `Update` *pushAll* `(String key, Object[] values)` 使用 `$pushAll` 更新修饰符进行更新
* `Update` *rename* `(String oldName, String newName)` 使用 `$rename` 更新修饰符进行更新
* `Update` *set* `(String key, Object value)` 使用 `$set` 更新修饰符进行更新
* `Update` *setOnInsert* `(String key, Object value)` 使用 `$setOnInsert` 更新修饰符进行更新
* `Update` *unset* `(String key)` 使用 `$unset` 更新修饰符进行更新

有些更新修饰符, 例如 `$push` 和 `$addToSet`, 允许嵌套附加的操作符.

[source]
----
// { $push : { "category" : { "$each" : [ "spring" , "data" ] } } }
new Update().push("category").each("spring", "data")

// { $push : { "key" : { "$position" : 0 , "$each" : [ "Arya" , "Arry" , "Weasel" ] } } }
new Update().push("key").atPosition(Position.FIRST).each(Arrays.asList("Arya", "Arry", "Weasel"));

// { $push : { "key" : { "$slice" : 5 , "$each" : [ "Arya" , "Arry" , "Weasel" ] } } }
new Update().push("key").slice(5).each(Arrays.asList("Arya", "Arry", "Weasel"));

// { $addToSet : { "values" : { "$each" : [ "spring" , "data" , "mongodb" ] } } }
new Update().addToSet("values").each("spring", "data", "mongodb");
----

[[mongo-template.upserts]]
=== 在集合中 "`Upserting`" Documents

与执行 `updateFirst` 操作相关，还可以执行 "`upsert`" 操作，如果没有找到与查询匹配的文档，则该操作将执行插入操作。插入的文档是查询文档和更新文档的组合。下面的例子展示了如何使用 `upsert` 方法:

[source]
----
template.update(Person.class)
  .matching(query(where("ssn").is(1111).and("firstName").is("Joe").and("Fraizer").is("Update"))
  .apply(update("address", addr))
  .upsert();
----

WARNING: `upsert` 不支持排序. 请使用 <<mongo-template.find-and-upsert, findAndModify>> 应用 `Sort`.

[[mongo-template.find-and-upsert]]
=== 在一个集合中 Finding 和 Upserting Documents

`MongoCollection` 的 `findAndModify(…)`  方法可以更新文档，并在单个操作中返回旧的或最新更新的文档。`MongoTemplate` 提供了四个 `findAndModify` 重载方法，它们接受 `Query` 和 `Update` 类，并将 `Document` 转换为 POJOs:

[source,java]
----
<T> T findAndModify(Query query, Update update, Class<T> entityClass);

<T> T findAndModify(Query query, Update update, Class<T> entityClass, String collectionName);

<T> T findAndModify(Query query, Update update, FindAndModifyOptions options, Class<T> entityClass);

<T> T findAndModify(Query query, Update update, FindAndModifyOptions options, Class<T> entityClass, String collectionName);
----

下面的例子将一些 `Person` 对象插入到容器中，并执行 `findAndUpdate` 操作:

[source,java]
----
template.insert(new Person("Tom", 21));
template.insert(new Person("Dick", 22));
template.insert(new Person("Harry", 23));

Query query = new Query(Criteria.where("firstName").is("Harry"));
Update update = new Update().inc("age", 1);

Person oldValue = template.update(Person.class)
  .matching(query)
  .apply(update)
  .findAndModifyValue(); // return's old person object

assertThat(oldValue.getFirstName()).isEqualTo("Harry");
assertThat(oldValue.getAge()).isEqualTo(23);

Person newValue = template.query(Person.class)
  .matching(query)
  .findOneValue();

assertThat(newValue.getAge()).isEqualTo(24);

Person newestValue = template.update(Person.class)
  .matching(query)
  .apply(update)
  .withOptions(FindAndModifyOptions.options().returnNew(true)) // Now return the newly updated document when updating
  .findAndModifyValue();

assertThat(newestValue.getAge()).isEqualTo(25);
----

`FindAndModifyOptions` 方法允许您设置 `returnNew`、`upsert` 和 `remove` 的选项。下面是前面代码片段的一个扩展示例:

[source,java]
----
Person upserted = template.update(Person.class)
  .matching(new Query(Criteria.where("firstName").is("Mary")))
  .apply(update)
  .withOptions(FindAndModifyOptions.options().upsert(true).returnNew(true))
  .findAndModifyValue()

assertThat(upserted.getFirstName()).isEqualTo("Mary");
assertThat(upserted.getAge()).isOne();
----

[[mongo-template.aggregation-update]]
=== 聚合管道更新(Aggregation Pipeline Updates)

由 `MongoOperations` 和 `ReactiveMongoOperations` 公开的更新方法也通过 `AggregationUpdate` 接受一个 <<mongo.aggregation, Aggregation Pipeline>>。使用 `AggregationUpdate` 允许在更新操作中利用 https://docs.mongodb.com/manual/reference/method/db.collection.update/#update-with-aggregation-pipeline[MongoDB 4.2 aggregations]。在更新中使用聚合可以通过一个操作表示多个阶段和多个条件来更新一个或多个字段。

更新可包括以下阶段:

* `AggregationUpdate.set(...).toValue(...)` -> `$set : { ... }`
* `AggregationUpdate.unset(...)` -> `$unset : [ ... ]`
* `AggregationUpdate.replaceWith(...)` -> `$replaceWith : { ... }`

.Update Aggregation
====
[source,java]
----
AggregationUpdate update = Aggregation.newUpdate()
    .set("average").toValue(ArithmeticOperators.valueOf("tests").avg())     <1>
    .set("grade").toValue(ConditionalOperators.switchCases(                 <2>
        when(valueOf("average").greaterThanEqualToValue(90)).then("A"),
        when(valueOf("average").greaterThanEqualToValue(80)).then("B"),
        when(valueOf("average").greaterThanEqualToValue(70)).then("C"),
        when(valueOf("average").greaterThanEqualToValue(60)).then("D"))
        .defaultTo("F")
    );

template.update(Student.class)                                              <3>
    .apply(update)
    .all();                                                                 <4>
----
[source,javascript]
----
db.students.update(                                                         <3>
   { },
   [
     { $set: { average : { $avg: "$tests" } } },                            <1>
     { $set: { grade: { $switch: {                                          <2>
                           branches: [
                               { case: { $gte: [ "$average", 90 ] }, then: "A" },
                               { case: { $gte: [ "$average", 80 ] }, then: "B" },
                               { case: { $gte: [ "$average", 70 ] }, then: "C" },
                               { case: { $gte: [ "$average", 60 ] }, then: "D" }
                           ],
                           default: "F"
     } } } }
   ],
   { multi: true }                                                          <4>
)
----
<1> 第一个 `$set` 阶段根据 _tests_ 字段的 _average_ 计算新的字段 _average_ 值。
<2> 第二个 `$set` 阶段根据第一个聚合阶段计算的 _average_ 字段计算一个新的 _grade_ 字段。
<3> 管道在  _students_  集合上运行，并使用  `Student`  进行聚合字段映射。
<4> 将更新应用于集合中的所有匹配文档。
====

[[mongo-template.find-and-replace]]
=== 查找和替换文件

替换整个 `Document` 最直接的方法是通过它的 `id` 使用 `save` 方法。然而，这并不总是可行的。`findAndReplace` 提供了一种替代方法，它允许通过一个简单的查询来标识要替换的文档。

.查找和替换文件
====
[source,java]
----
Optional<User> result = template.update(Person.class)      <1>
    .matching(query(where("firstame").is("Tom")))          <2>
    .replaceWith(new Person("Dick"))
    .withOptions(FindAndReplaceOptions.options().upsert()) <3>
    .as(User.class)                                        <4>
    .findAndReplace();                                     <5>
----
<1> 对于给定的 domain 类型，使用流式更新 API 来映射查询并派生集合名称，或者只使用 `MongoOperations#findAndReplace`。
<2> 实际的匹配查询映射到给定的 domain 类型。通过查询提供 `sort`, `fields` 和 `collation` 设置。
<3> 额外的可选钩子提供默认值以外的选项，比如 `upsert`。
<4> 用于映射操作结果的可选投影类型。如果没有给定，则使用初始 domain 类型。
<5> 触发实际处理。使用 `findAndReplaceValue` 获取可空结果而不是 `Optional` 结果。
====

IMPORTANT: 请注意，替换的文档不能有 `id` 本身，因为现有文档的 `id` 将由存储本身转入替换的文档。还要记住，根据可能给定的排序顺序，`findAndReplace` 将只替换与查询条件匹配的第一个文档。

[[mongo-template.delete]]
=== 删除 Documents 的方法

你可以使用五种重载方法中的一种从数据库中删除对象:

====
[source,java]
----
template.remove(tywin, "GOT");                                              <1>

template.remove(query(where("lastname").is("lannister")), "GOT");           <2>

template.remove(new Query().limit(3), "GOT");                               <3>

template.findAllAndRemove(query(where("lastname").is("lannister"), "GOT");  <4>

template.findAllAndRemove(new Query().limit(3), "GOT");                     <5>
----
<1> 从关联集合中移除单个由 `_id` 指定的实体
<2> 从 `GOT` 集合中删除符合查询条件的所有文档。
<3> 删除 `GOT` 集合中的前三个文档。与 <2> 不同，要删除的文档由它们的 `_id` 标识，运行给定的查询，首先应用 `sort`、`limit` 和 `skip` 选项，然后在单独的步骤中一次性删除所有选项。
<4> 从 `GOT` 集合中删除匹配查询条件的所有文档。与 <3> 不同，文档不是在批处理中删除的，而是一个一个地删除。
<5> 删除 `GOT` 集合中的前三个文档。与 <3> 不同，文档不是在批处理中删除的，而是一个一个地删除。
====

[[mongo-template.optimistic-locking]]
=== 乐观锁

`@Version`  注解提供了类似于 `MongoDB` 上下文中 JPA 的语法，并确保更新只应用于具有匹配版本的文档。因此，version 属性的实际值被添加到更新查询中，这样一来，如果在此期间另一个操作改变了文档，则更新不会产生任何影响。在这种情况下，抛出一个 `OptimisticLockingFailureException`。下面的例子展示了这些特性:

====
[source,java]
----
@Document
class Person {

  @Id String id;
  String firstname;
  String lastname;
  @Version Long version;
}

Person daenerys = template.insert(new Person("Daenerys"));                            <1>

Person tmp = template.findOne(query(where("id").is(daenerys.getId())), Person.class); <2>

daenerys.setLastname("Targaryen");
template.save(daenerys);                                                              <3>

template.save(tmp); // throws OptimisticLockingFailureException                       <4>
----
<1> 开始插入文档。`version` 设置为 `0`。
<2> 加载刚插入的文档。`version` 仍然是 `0`。
<3> 用 `version = 0` 更新文档。将 `lastname` 和 bump `version` 设置为 `1`。
<4> 尝试更新先前加载的仍然 `version = 0` 的文档。由于当前版本为 `1`，该操作会以 `OptimisticLockingFailureException` 异常失败。
====

IMPORTANT: 乐观锁需要将 `WriteConcern` 设置为 `ACKNOWLEDGED`。否则，`OptimisticLockingFailureException` 可以被接受。

NOTE: 从 2.2 版本开始，当从数据库中删除实体时，`MongoOperations` 也包含了 `@Version` 属性。要删除一个没有版本检查的文档，请使用 `MongoOperations#remove(Query,...)` 而不是 `MongoOperations#remove(Object)` 。

NOTE: 从 2.2 版本开始，存储库在删除具有版本实体时检查确认删除的结果。如果一个具有版本的实体不能通过 `CrudRepository.delete(Object)` 删除，则会引发 `OptimisticLockingFailureException`。在这种情况下，版本发生了变化或者对象被删除。使用 `CrudRepository.deleteById(ID)` 绕过乐观锁功能，并删除对象，无论其版本如何。

[[mongo.query]]
== 查询 Documents

你可以使用 `Query` 和 `Criteria` 来进行查询。他们具有与原生 MongoDB 操作符相同的方法名称。例如，`lt`, `lte`, `is` 等。`Query` 和 `Criteria` 类具有流式 API，这样，您可以进行链式构建多种查询方法，同时也具有更高的可读性。静态导入使您不用使用 'new' 关键字来创建  `Query` 和 `Criteria` 实例。您还可以使用 `BasicQuery` 从普通 json 字符串创建查询实例，如以下示例所示：

.从 JSON 字符串创建一个 Query 实例
====
[source,java]
----
BasicQuery query = new BasicQuery("{ age : { $lt : 50 }, accounts.balance : { $gt : 1000.00 }}");
List<Person> result = mongoTemplate.find(query, Person.class);
----
====

Spring MongoDB  还支持 GeoSpatial 查询  (查看 <<mongo.geospatial,GeoSpatial Queries>> 章节)，Map-Reduce 操作 (查看 <<mongo.mapreduce,Map-Reduce>> 章节).

[[mongodb-template-query]]
=== 从集合中查询文档

在文档的前面，我们使用  `MongoTemplate` 的 `findOne` 和 `findById` 方法来查询单个文档，这些方法返回一个 domain 对象。我们还可以查询 domain 对象的集合。假设，我们有许多 `Person` 对象，它具有 name 和 age 属性，并且具有一个嵌入的 balance 对象，我们现在可以使用以下代码运行查询：:

.使用 MongoTemplate 查询文档
====
[source,java]
----
import static org.springframework.data.mongodb.core.query.Criteria.where;
import static org.springframework.data.mongodb.core.query.Query.query;

// ...

List<Person> result = template.query(Person.class)
  .matching(query(where("age").lt(50).and("accounts.balance").gt(1000.00d)))
  .all();
----
====

所有的 find 方法都以一个 `Query` 对象作为参数。此对象定义用于执行查询的条件和选项。criteria 是通过使用 `Criteria` 对象指定的，该对象具有一个静态工厂方法  `where`，该方法用于实例化一个新的 `Criteria` 对象。我们建议对 `org.springframework.data.mongodb.core.query.Criteria.where` 和 `Query` 使用静态导入。`Query.query` 更具可读性。

该查询返回满足指定条件的 `Person` 对象列表。本节的其余部分列出了与 MongoDB 提供的操作符相对应的 `Criteria` 和 `Query` 类的方法。大多数方法返回 `Criteria` 对象，为 API 提供流式风格。

[[mongodb-template-query.criteria]]
==== Criteria 类方法

`Criteria` 类提供了以下方法，它们都对应 MongoDB 中的操作符:

* `Criteria` *all* `(Object o)` 使用 `$all` 操作符创建一个 criterion。
* `Criteria` *and* `(String key)` 将指定的 `key`  的  `Criteria` 链接到当前的 `Criteria` 并返回新创建的 `Criteria` 。
* `Criteria` *andOperator* `(Criteria... criteria)` 使用  `$and`  操作符为所有提供的条件创建一个 and 查询(需要 MongoDB 2.0 或更高版本)。
* `Criteria` *elemMatch* `(Criteria c)` 使用 `$elemMatch` 操作符创建一个 criterion。
* `Criteria` *exists* `(boolean b)` 使用 `$exists` 操作符创建一个 criterion。
* `Criteria` *gt* `(Object o)` 使用 `$gt` 操作符创建一个 criterion。
* `Criteria` *gte* `(Object o)` 使用 `$gte` 操作符创建一个 criterion。
* `Criteria` *in* `(Object... o)` 为 varargs 参数使用 `$in` 操作符创建一个 criterion。
* `Criteria` *in* `(Collection<?> collection)` 使用集合 `$in` 操作符创建一个 criterion。
* `Criteria` *is* `(Object o)` 使用字段匹配 (`{ key:value }`) 创建一个条件. 如果指定的值是一个文档，则字段的顺序和文档中的确切相等性很重要。
* `Criteria` *lt* `(Object o)` 使用 `$lt` 操作符创建一个 criterion。
* `Criteria` *lte* `(Object o)` 使用 `$lte` 操作符创建一个 criterion。
* `Criteria` *mod* `(Number value, Number remainder)` 使用 `$mod` 操作符创建一个 criterion。
* `Criteria` *ne* `(Object o)` 使用 `$ne` 操作符创建一个 criterion。
* `Criteria` *nin* `(Object... o)` 使用 `$nin` 操作符创建一个 criterion。
* `Criteria` *norOperator* `(Criteria... criteria)` 使用 `$nor` 操作符为所有提供的条件创建一个 nor 查询。
* `Criteria` *not* `()` 使用 `$not` meta 操作符创建一个条件，它会直接影响后面的子句。
* `Criteria` *orOperator* `(Criteria... criteria)` 使用 `$or` 操作符为所有提供的条件创建一个查询。
* `Criteria` *regex* `(String re)` 使用 `$regex` 操作符创建一个 criterion。
* `Criteria` *size* `(int s)` 使用 `$size` 操作符创建一个 criterion。
* `Criteria` *type* `(int t)` 使用 `$type` 操作符创建一个 criterion。
* `Criteria` *matchingDocumentStructure* `(MongoJsonSchema schema)` 使用 `$jsonSchema` 操作符创建一个 <<mongo.jsonSchema,JSON schema criteria>>. `$jsonSchema` 只能应用在查询的顶层，而不是特定的属性。使用 schema 的 `properties` 属性来匹配嵌套的字段。
* `Criteria` *bits()* 是 https://docs.mongodb.com/manual/reference/operator/query-bitwise/[MongoDB bitwise query operators] 操作符的网关 `$bitsAllClear`.


Criteria 类还提供了以下用于地理空间查询的方法（请参阅 <<mongo.geospatial,GeoSpatial Queries>> 部分中查看它们）：

* `Criteria` *within* `(Circle circle)` 使用 `$geoWithin $center` 操作符创建地理空间条件.
* `Criteria` *within* `(Box box)` 使用 `$geoWithin $box` 操作符创建地理空间条件.
* `Criteria` *withinSphere* `(Circle circle)` 使用 `$geoWithin $center` 操作符创建地理空间条件.
* `Criteria` *near* `(Point point)` 使用 `$near` 操作符创建地理空间条件。
* `Criteria` *nearSphere* `(Point point)` 使用 `$nearSphere$center` 操作符创建地理空间条件，这只适用于MongoDB 1.7和更高版本。
* `Criteria` *minDistance* `(double minDistance)` 使用 `$minDistance` 操作符创建地理空间条件，用于与 $near 一起使用。
* `Criteria` *maxDistance* `(double maxDistance)` 使用 `$maxDistance` 操作符创建地理空间条件，用于与 $near 一起使用。


[[mongodb-template-query.query]]
==== Query 类的方法

`Query` 有一些其他方法为查询提供选项:

* `Query` *addCriteria* `(Criteria criteria)` 用于向查询添加附加条件
* `Field` *fields* `()` 用于定义在查询中包含的字段
* `Query` *limit* `(int limit)` 用于将返回结果的大小限制在所提供的限制范围内(用于分页)
* `Query` *skip* `(int skip)` 用于跳过结果中提供的文档数量(用于分页)
* `Query` *with* `(Sort sort)` 用于为结果提供排序定义

[[mongo-template.querying]]
=== 查询文档的方法

查询方法需要指定返回的类型 `T` ，对于应该操作由返回类型指示的集合以外的集合的查询，查询方法使用显式声明的集合名重载。下面的查询方法可以让你找到一个或多个文档:

* *findAll*: 查询来自集合的 `T` 类型的对象列表.
* *findOne*: 将 ad-hoc 查询的结果映射到指定类型的对象的单个实例.
* *findById*: 根据 ID 查询对象.
* *find*: 将 ad-hoc 查询的结果映射到指定类型的列表.
* *findAndRemove*: 将 ad-hoc 查询的结果映射到指定类型的对象的单个实例。返回匹配查询的第一个文档并从数据库的集合中删除。.

[[mongo-template.query.distinct]]
=== 查询不同的值

MongoDB 可以从查询结果中获取同一个字段的不同值。
结果值不需要具有相同的数据类型，也不局限于简单的类型。对于检索来说，真实的结果类型确实很重要，以便于进行转换和类型化。下面的示例演示如何查询不同的值。:

.Retrieving distinct values
====
[source,java]
----
template.query(Person.class)  <1>
  .distinct("lastname")       <2>
  .all();                     <3>
----
<1> 查询 `Person` 集合.
<2> 获取 `lastname` 字段的不同值，字段名称根据实体类型属性进行映射，并考虑 `@Field` 上的注解.
<3> 检索所有的不同值的对象列表 (由于未指定明确的结果类型).
====

将不同的值检索到  `Object` 集合中是最灵活的方式，因为它尝试确定 domain 类型的属性值并将结果转换为所需的类型或映射文档结构.

有时，当所需字段的所有值都固定为某一类型时，直接获取正确类型的集合会更方便，如下例所示:

.Retrieving strongly typed distinct values
====
[source,java]
----
template.query(Person.class)  <1>
  .distinct("lastname")       <2>
  .as(String.class)           <3>
  .all();                     <4>
----
<1> 查询 `Person` 集合.
<2> 获取 `lastname` 字段的不同值，字段名称根据实体类型属性进行映射，并考虑 `@Field` 上的注解。.
<3> 检索到的值被转换为所需的目标类型 -- 在本例中为 `String`. 如果存储的字段包含文档，也可以将值映射到更复杂的类型。
<4> 以字符串列表的形式检索所有不同的值。如果无法将类型转换为所需的目标类型，此方法将抛出 `DataAccessException`.
====

[[mongo.geospatial]]
=== GeoSpatial Queries

MongoDB supports GeoSpatial queries through the use of operators such as `$near`, `$within`, `geoWithin`, and `$nearSphere`. Methods specific to geospatial queries are available on the `Criteria` class. There are also a few shape classes (`Box`, `Circle`, and `Point`) that are used in conjunction with geospatial related `Criteria` methods.

NOTE: Using GeoSpatial queries requires attention when used within MongoDB transactions, see <<mongo.transactions.behavior>>.

To understand how to perform GeoSpatial queries, consider the following `Venue` class (taken from the integration tests and relying on the rich `MappingMongoConverter`):

[source,java]
----
@Document(collection="newyork")
public class Venue {

  @Id
  private String id;
  private String name;
  private double[] location;

  @PersistenceConstructor
  Venue(String name, double[] location) {
    super();
    this.name = name;
    this.location = location;
  }

  public Venue(String name, double x, double y) {
    super();
    this.name = name;
    this.location = new double[] { x, y };
  }

  public String getName() {
    return name;
  }

  public double[] getLocation() {
    return location;
  }

  @Override
  public String toString() {
    return "Venue [id=" + id + ", name=" + name + ", location="
        + Arrays.toString(location) + "]";
  }
}
----

To find locations within a `Circle`, you can use the following query:

[source,java]
----
Circle circle = new Circle(-73.99171, 40.738868, 0.01);
List<Venue> venues =
    template.find(new Query(Criteria.where("location").within(circle)), Venue.class);
----

To find venues within a `Circle` using spherical coordinates, you can use the following query:

[source,java]
----
Circle circle = new Circle(-73.99171, 40.738868, 0.003712240453784);
List<Venue> venues =
    template.find(new Query(Criteria.where("location").withinSphere(circle)), Venue.class);
----

To find venues within a `Box`, you can use the following query:

[source,java]
----
//lower-left then upper-right
Box box = new Box(new Point(-73.99756, 40.73083), new Point(-73.988135, 40.741404));
List<Venue> venues =
    template.find(new Query(Criteria.where("location").within(box)), Venue.class);
----

To find venues near a `Point`, you can use the following queries:

[source,java]
----
Point point = new Point(-73.99171, 40.738868);
List<Venue> venues =
    template.find(new Query(Criteria.where("location").near(point).maxDistance(0.01)), Venue.class);
----

[source,java]
----
Point point = new Point(-73.99171, 40.738868);
List<Venue> venues =
    template.find(new Query(Criteria.where("location").near(point).minDistance(0.01).maxDistance(100)), Venue.class);
----

To find venues near a `Point` using spherical coordinates, you can use the following query:

[source,java]
----
Point point = new Point(-73.99171, 40.738868);
List<Venue> venues =
    template.find(new Query(
        Criteria.where("location").nearSphere(point).maxDistance(0.003712240453784)),
        Venue.class);
----

[[mongo.geo-near]]
==== Geo-near Queries

[WARNING]
====
*Changed in 2.2!* +
https://docs.mongodb.com/master/release-notes/4.2-compatibility/[MongoDB 4.2] removed support for the
`geoNear` command which had been previously used to run the `NearQuery`.

Spring Data MongoDB 2.2 `MongoOperations#geoNear` uses the `$geoNear` https://docs.mongodb.com/manual/reference/operator/aggregation/geoNear/[aggregation]
instead of the `geoNear` command to run a `NearQuery`.

The calculated distance (the `dis` when using a geoNear command) previously returned within a wrapper type now is embedded
into the resulting document.
If the given domain type already contains a property with that name, the calculated distance
is named `calculated-distance` with a potentially random postfix.

Target types may contain a property named after the returned distance to (additionally) read it back directly into the domain type as shown below.

[source,java]
----
GeoResults<VenueWithDisField> = template.query(Venue.class) <1>
    .as(VenueWithDisField.class)                            <2>
    .near(NearQuery.near(new GeoJsonPoint(-73.99, 40.73), KILOMETERS))
    .all();
----
<1> Domain type used to identify the target collection and potential query mapping.
<2> Target type containing a `dis` field of type `Number`.
====

MongoDB supports querying the database for geo locations and calculating the distance from a given origin at the same time. With geo-near queries, you can express queries such as "find all restaurants in the surrounding 10 miles". To let you do so, `MongoOperations` provides `geoNear(…)` methods that take a `NearQuery` as an argument (as well as the already familiar entity type and collection), as shown in the following example:

[source,java]
----
Point location = new Point(-73.99171, 40.738868);
NearQuery query = NearQuery.near(location).maxDistance(new Distance(10, Metrics.MILES));

GeoResults<Restaurant> = operations.geoNear(query, Restaurant.class);
----

We use the `NearQuery` builder API to set up a query to return all `Restaurant` instances surrounding the given `Point` out to 10 miles. The `Metrics` enum used here actually implements an interface so that other metrics could be plugged into a distance as well. A `Metric` is backed by a multiplier to transform the distance value of the given metric into native distances. The sample shown here would consider the 10 to be miles. Using one of the built-in metrics (miles and kilometers) automatically triggers the spherical flag to be set on the query. If you want to avoid that, pass plain `double` values into `maxDistance(…)`. For more information, see the https://docs.spring.io/spring-data/mongodb/docs/{version}/api/index.html[JavaDoc] of `NearQuery` and `Distance`.

The geo-near operations return a `GeoResults` wrapper object that encapsulates `GeoResult` instances. Wrapping `GeoResults` allows accessing the average distance of all results. A single `GeoResult` object carries the entity found plus its distance from the origin.

[[mongo.geo-json]]
=== GeoJSON Support

MongoDB supports https://geojson.org/[GeoJSON] and simple (legacy) coordinate pairs for geospatial data. Those formats can both be used for storing as well as querying data. See the https://docs.mongodb.org/manual/core/2dsphere/#geospatial-indexes-store-geojson/[MongoDB manual on GeoJSON support] to learn about requirements and restrictions.

[[mongo.geo-json.domain.classes]]
==== GeoJSON Types in Domain Classes

Usage of https://geojson.org/[GeoJSON] types in domain classes is straightforward. The `org.springframework.data.mongodb.core.geo` package contains types such as `GeoJsonPoint`, `GeoJsonPolygon`, and others. These types are extend the existing `org.springframework.data.geo` types. The following example uses a `GeoJsonPoint`:

====
[source,java]
----
public class Store {

	String id;

	/**
	 * location is stored in GeoJSON format.
	 * {
	 *   "type" : "Point",
	 *   "coordinates" : [ x, y ]
	 * }
	 */
	GeoJsonPoint location;
}
----
====

[[mongo.geo-json.query-methods]]
==== GeoJSON Types in Repository Query Methods

Using GeoJSON types as repository query parameters forces usage of the `$geometry` operator when creating the query, as the following example shows:

====
[source,java]
----
public interface StoreRepository extends CrudRepository<Store, String> {

	List<Store> findByLocationWithin(Polygon polygon);  <1>

}

/*
 * {
 *   "location": {
 *     "$geoWithin": {
 *       "$geometry": {
 *         "type": "Polygon",
 *         "coordinates": [
 *           [
 *             [-73.992514,40.758934],
 *             [-73.961138,40.760348],
 *             [-73.991658,40.730006],
 *             [-73.992514,40.758934]
 *           ]
 *         ]
 *       }
 *     }
 *   }
 * }
 */
repo.findByLocationWithin(                              <2>
  new GeoJsonPolygon(
    new Point(-73.992514, 40.758934),
    new Point(-73.961138, 40.760348),
    new Point(-73.991658, 40.730006),
    new Point(-73.992514, 40.758934)));                 <3>

/*
 * {
 *   "location" : {
 *     "$geoWithin" : {
 *        "$polygon" : [ [-73.992514,40.758934] , [-73.961138,40.760348] , [-73.991658,40.730006] ]
 *     }
 *   }
 * }
 */
repo.findByLocationWithin(                              <4>
  new Polygon(
    new Point(-73.992514, 40.758934),
    new Point(-73.961138, 40.760348),
    new Point(-73.991658, 40.730006)));
----
<1> Repository method definition using the commons type allows calling it with both the GeoJSON and the legacy format.
<2> Use GeoJSON type to make use of `$geometry` operator.
<3> Note that GeoJSON polygons need to define a closed ring.
<4> Use the legacy format `$polygon` operator.
====

[[mongo.geo-json.metrics]]
==== Metrics and Distance calculation

Then MongoDB `$geoNear` operator allows usage of a GeoJSON Point or legacy coordinate pairs.

====
[source,java]
----
NearQuery.near(new Point(-73.99171, 40.738868))
----
[source,json]
----
{
  "$geoNear": {
    //...
    "near": [-73.99171, 40.738868]
  }
}
----
====
====
[source,java]
----
NearQuery.near(new GeoJsonPoint(-73.99171, 40.738868))
----
[source,json]
----
{
  "$geoNear": {
    //...
    "near": { "type": "Point", "coordinates": [-73.99171, 40.738868] }
  }
}

----
====

Though syntactically different the server is fine accepting both no matter what format the target Document within the collection
is using.

WARNING: There is a huge difference in the distance calculation. Using the legacy format operates
upon _Radians_ on an Earth like sphere, whereas the GeoJSON format uses _Meters_.

To avoid a serious headache make sure to set the `Metric` to the desired unit of measure which ensures the
distance to be calculated correctly.

In other words:

====
Assume you've got 5 Documents like the ones below:
[source,json]
----
{
    "_id" : ObjectId("5c10f3735d38908db52796a5"),
    "name" : "Penn Station",
    "location" : { "type" : "Point", "coordinates" : [  -73.99408, 40.75057 ] }
}
{
    "_id" : ObjectId("5c10f3735d38908db52796a6"),
    "name" : "10gen Office",
    "location" : { "type" : "Point", "coordinates" : [ -73.99171, 40.738868 ] }
}
{
    "_id" : ObjectId("5c10f3735d38908db52796a9"),
    "name" : "City Bakery ",
    "location" : { "type" : "Point", "coordinates" : [ -73.992491, 40.738673 ] }
}
{
    "_id" : ObjectId("5c10f3735d38908db52796aa"),
    "name" : "Splash Bar",
    "location" : { "type" : "Point", "coordinates" : [ -73.992491, 40.738673 ] }
}
{
    "_id" : ObjectId("5c10f3735d38908db52796ab"),
    "name" : "Momofuku Milk Bar",
    "location" : { "type" : "Point", "coordinates" : [ -73.985839, 40.731698 ] }
}
----
====

Fetching all Documents within a 400 Meter radius from `[-73.99171, 40.738868]` would look like this using
GeoJSON:

.GeoNear with GeoJSON
====
[source,json]
----
{
    "$geoNear": {
        "maxDistance": 400, <1>
        "num": 10,
        "near": { type: "Point", coordinates: [-73.99171, 40.738868] },
        "spherical":true, <2>
        "key": "location",
        "distanceField": "distance"
    }
}
----
Returning the following 3 Documents:
[source,json]
----
{
    "_id" : ObjectId("5c10f3735d38908db52796a6"),
    "name" : "10gen Office",
    "location" : { "type" : "Point", "coordinates" : [ -73.99171, 40.738868 ] }
    "distance" : 0.0 <3>
}
{
    "_id" : ObjectId("5c10f3735d38908db52796a9"),
    "name" : "City Bakery ",
    "location" : { "type" : "Point", "coordinates" : [ -73.992491, 40.738673 ] }
    "distance" : 69.3582262492474 <3>
}
{
    "_id" : ObjectId("5c10f3735d38908db52796aa"),
    "name" : "Splash Bar",
    "location" : { "type" : "Point", "coordinates" : [ -73.992491, 40.738673 ] }
    "distance" : 69.3582262492474 <3>
}
----
<1> Maximum distance from center point in _Meters_.
<2> GeoJSON always operates upon a sphere.
<3> Distance from center point in _Meters_.
====

Now, when using legacy coordinate pairs one operates upon _Radians_ as discussed before. So we use `Metrics#KILOMETERS
when constructing the `$geoNear` command. The `Metric` makes sure the distance multiplier is set correctly.

.GeoNear with Legacy Coordinate Pairs
====
[source,json]
----
{
    "$geoNear": {
        "maxDistance": 0.0000627142377, <1>
        "distanceMultiplier": 6378.137, <2>
        "num": 10,
        "near": [-73.99171, 40.738868],
        "spherical":true, <3>
        "key": "location",
        "distanceField": "distance"
    }
}
----
Returning the 3 Documents just like the GeoJSON variant:
[source,json]
----
{
    "_id" : ObjectId("5c10f3735d38908db52796a6"),
    "name" : "10gen Office",
    "location" : { "type" : "Point", "coordinates" : [ -73.99171, 40.738868 ] }
    "distance" : 0.0 <4>
}
{
    "_id" : ObjectId("5c10f3735d38908db52796a9"),
    "name" : "City Bakery ",
    "location" : { "type" : "Point", "coordinates" : [ -73.992491, 40.738673 ] }
    "distance" : 0.0693586286032982 <4>
}
{
    "_id" : ObjectId("5c10f3735d38908db52796aa"),
    "name" : "Splash Bar",
    "location" : { "type" : "Point", "coordinates" : [ -73.992491, 40.738673 ] }
    "distance" : 0.0693586286032982 <4>
}
----
<1> Maximum distance from center point in _Radians_.
<2> The distance multiplier so we get _Kilometers_ as resulting distance.
<3> Make sure we operate on a 2d_sphere index.
<4> Distance from center point in _Kilometers_ - take it times 1000 to match _Meters_ of the GeoJSON variant.
====

[[mongo.geo-json.jackson-modules]]
==== GeoJSON Jackson Modules

By using the <<core.web>>, Spring Data registers additional Jackson ``Modules``s to the `ObjectMapper` for deserializing common Spring Data domain types.
Please refer to the <<core.web.basic.jackson-mappers>> section to learn more about the infrastructure setup of this feature.

The MongoDB module additionally registers ``JsonDeserializer``s for the following GeoJSON types via its `GeoJsonConfiguration` exposing the `GeoJsonModule`.
----
org.springframework.data.mongodb.core.geo.GeoJsonPoint
org.springframework.data.mongodb.core.geo.GeoJsonMultiPoint
org.springframework.data.mongodb.core.geo.GeoJsonLineString
org.springframework.data.mongodb.core.geo.GeoJsonMultiLineString
org.springframework.data.mongodb.core.geo.GeoJsonPolygon
org.springframework.data.mongodb.core.geo.GeoJsonMultiPolygon
----

[NOTE]
====
The `GeoJsonModule` only registers ``JsonDeserializer``s!

The next major version (`4.0`) will register both, ``JsonDeserializer``s and ``JsonSerializer``s for GeoJSON types by default.
====

[[mongo.textsearch]]
=== Full-text Queries

Since version 2.6 of MongoDB, you can run full-text queries by using the `$text` operator. Methods and operations specific to full-text queries are available in `TextQuery` and `TextCriteria`. When doing full text search, see the https://docs.mongodb.org/manual/reference/operator/query/text/#behavior[MongoDB reference] for its behavior and limitations.

==== Full-text Search

Before you can actually use full-text search, you must set up the search index correctly. See <<mapping-usage-indexes.text-index,Text Index>> for more detail on how to create index structures. The following example shows how to set up a full-text search:

[source,javascript]
----
db.foo.createIndex(
{
  title : "text",
  content : "text"
},
{
  weights : {
              title : 3
            }
}
)
----

A query searching for `coffee cake` can be defined and run as follows:

.Full Text Query
====
[source,java]
----
Query query = TextQuery
  .queryText(new TextCriteria().matchingAny("coffee", "cake"));

List<Document> page = template.find(query, Document.class);
----
====

To sort results by relevance according to the `weights` use `TextQuery.sortByScore`.

.Full Text Query - Sort by Score
====
[source,java]
----
Query query = TextQuery
  .queryText(new TextCriteria().matchingAny("coffee", "cake"))
  .sortByScore() <1>
  .includeScore(); <2>

List<Document> page = template.find(query, Document.class);
----
<1> Use the score property for sorting results by relevance which triggers `.sort({'score': {'$meta': 'textScore'}})`.
<2> Use `TextQuery.includeScore()` to include the calculated relevance in the resulting `Document`.
====

You can exclude search terms by prefixing the term with `-` or by using `notMatching`, as shown in the following example (note that the two lines have the same effect and are thus redundant):

[source,java]
----
// search for 'coffee' and not 'cake'
TextQuery.queryText(new TextCriteria().matching("coffee").matching("-cake"));
TextQuery.queryText(new TextCriteria().matching("coffee").notMatching("cake"));
----

`TextCriteria.matching` takes the provided term as is. Therefore, you can define phrases by putting them between double quotation marks (for example, `\"coffee cake\")` or using by `TextCriteria.phrase.` The following example shows both ways of defining a phrase:

[source,java]
----
// search for phrase 'coffee cake'
TextQuery.queryText(new TextCriteria().matching("\"coffee cake\""));
TextQuery.queryText(new TextCriteria().phrase("coffee cake"));
----

You can set flags for `$caseSensitive` and `$diacriticSensitive` by using the corresponding methods on `TextCriteria`. Note that these two optional flags have been introduced in MongoDB 3.2 and are not included in the query unless explicitly set.

[[mongo.collation]]
=== Collations

Since version 3.4, MongoDB supports collations for collection and index creation and various query operations. Collations define string comparison rules based on the http://userguide.icu-project.org/collation/concepts[ICU collations]. A collation document consists of various properties that are encapsulated in `Collation`, as the following listing shows:

====
[source,java]
----
Collation collation = Collation.of("fr")         <1>

  .strength(ComparisonLevel.secondary()          <2>
    .includeCase())

  .numericOrderingEnabled()                      <3>

  .alternate(Alternate.shifted().punct())        <4>

  .forwardDiacriticSort()                        <5>

  .normalizationEnabled();                       <6>
----
<1> `Collation` requires a locale for creation. This can be either a string representation of the locale, a `Locale` (considering language, country, and variant) or a `CollationLocale`. The locale is mandatory for creation.
<2> Collation strength defines comparison levels that denote differences between characters. You can configure various options (case-sensitivity, case-ordering, and others), depending on the selected strength.
<3> Specify whether to compare numeric strings as numbers or as strings.
<4> Specify whether the collation should consider whitespace and punctuation as base characters for purposes of comparison.
<5> Specify whether strings with diacritics sort from back of the string, such as with some French dictionary ordering.
<6> Specify whether to check whether text requires normalization and whether to perform normalization.
====

Collations can be used to create collections and indexes. If you create a collection that specifies a collation, the
collation is applied to index creation and queries unless you specify a different collation. A collation is valid for a
whole operation and cannot be specified on a per-field basis.

Like other metadata, collations can be be derived from the domain type via the `collation` attribute of the `@Document`
annotation and will be applied directly when running queries, creating collections or indexes.

NOTE: Annotated collations will not be used when a collection is auto created by MongoDB on first interaction. This would
require additional store interaction delaying the entire process. Please use `MongoOperations.createCollection` for those cases.

[source,java]
----
Collation french = Collation.of("fr");
Collation german = Collation.of("de");

template.createCollection(Person.class, CollectionOptions.just(collation));

template.indexOps(Person.class).ensureIndex(new Index("name", Direction.ASC).collation(german));
----

NOTE: MongoDB uses simple binary comparison if no collation is specified (`Collation.simple()`).

Using collations with collection operations is a matter of specifying a `Collation` instance in your query or operation options, as the following two examples show:

.Using collation with `find`
====
[source,java]
----
Collation collation = Collation.of("de");

Query query = new Query(Criteria.where("firstName").is("Amél")).collation(collation);

List<Person> results = template.find(query, Person.class);
----
====

.Using collation with `aggregate`
====
[source,java]
----
Collation collation = Collation.of("de");

AggregationOptions options = AggregationOptions.builder().collation(collation).build();

Aggregation aggregation = newAggregation(
  project("tags"),
  unwind("tags"),
  group("tags")
    .count().as("count")
).withOptions(options);

AggregationResults<TagCount> results = template.aggregate(aggregation, "tags", TagCount.class);
----
====

WARNING: Indexes are only used if the collation used for the operation matches the index collation.

<<mongo.repositories>> support `Collations` via the `collation` attribute of the `@Query` annotation.

.Collation support for Repositories
====
[source,java]
----
public interface PersonRepository extends MongoRepository<Person, String> {

  @Query(collation = "en_US")  <1>
  List<Person> findByFirstname(String firstname);

  @Query(collation = "{ 'locale' : 'en_US' }") <2>
  List<Person> findPersonByFirstname(String firstname);

  @Query(collation = "?1") <3>
  List<Person> findByFirstname(String firstname, Object collation);

  @Query(collation = "{ 'locale' : '?1' }") <4>
  List<Person> findByFirstname(String firstname, String collation);

  List<Person> findByFirstname(String firstname, Collation collation); <5>

  @Query(collation = "{ 'locale' : 'en_US' }")
  List<Person> findByFirstname(String firstname, @Nullable Collation collation); <6>
}
----
<1> Static collation definition resulting in `{ 'locale' : 'en_US' }`.
<2> Static collation definition resulting in `{ 'locale' : 'en_US' }`.
<3> Dynamic collation depending on 2nd method argument. Allowed types include `String` (eg. 'en_US'), `Locacle` (eg. Locacle.US)
and `Document` (eg. new Document("locale", "en_US"))
<4> Dynamic collation depending on 2nd method argument.
<5> Apply the `Collation` method parameter to the query.
<6> The `Collation` method parameter overrides the default `collation` from `@Query` if not null.

NOTE: In case you enabled the automatic index creation for repository finder methods a potential static collation definition,
as shown in (1) and (2), will be included when creating the index.

TIP: The most specifc `Collation` outroules potentially defined others. Which means Method argument over query method annotation over doamin type annotation.
====

include::./mongo-json-schema.adoc[leveloffset=+1]

[[mongo.query.fluent-template-api]]
=== Fluent Template API

The `MongoOperations` interface is one of the central components when it comes to more low-level interaction with MongoDB. It offers a wide range of methods covering needs from collection creation, index creation, and CRUD operations to more advanced functionality, such as Map-Reduce and aggregations.
You can find multiple overloads for each method. Most of them cover optional or nullable parts of the API.

`FluentMongoOperations` provides a more narrow interface for the common methods of `MongoOperations` and provides a more readable, fluent API.
The entry points (`insert(…)`, `find(…)`, `update(…)`, and others) follow a natural naming schema based on the operation to be run. Moving on from the entry point, the API is designed to offer only context-dependent methods that lead to a terminating method that invokes the actual `MongoOperations` counterpart -- the `all` method in the case of the following example:

====
[source,java]
----
List<SWCharacter> all = ops.find(SWCharacter.class)
  .inCollection("star-wars")                        <1>
  .all();
----
<1> Skip this step if `SWCharacter` defines the collection with `@Document` or if you use the class name as the collection name, which is fine.
====

Sometimes, a collection in MongoDB holds entities of different types, such as a `Jedi` within a collection of `SWCharacters`.
To use different types for `Query` and return value mapping, you can use `as(Class<?> targetType)` to map results differently, as the following example shows:

====
[source,java]
----
List<Jedi> all = ops.find(SWCharacter.class)    <1>
  .as(Jedi.class)                               <2>
  .matching(query(where("jedi").is(true)))
  .all();
----
<1> The query fields are mapped against the `SWCharacter` type.
<2> Resulting documents are mapped into `Jedi`.
====

TIP: You can directly apply <<projections>> to result documents by providing the target type via `as(Class<?>)`.

NOTE: Using projections allows `MongoTemplate` to optimize result mapping by limiting the actual response to fields required
by the projection target type. This applies as long as the `Query` itself does not contain any field restriction and the
target type is a closed interface or DTO projection.

You can switch between retrieving a single entity and retrieving multiple entities as a `List` or a `Stream` through the terminating methods: `first()`, `one()`, `all()`, or `stream()`.

When writing a geo-spatial query with `near(NearQuery)`, the number of terminating methods is altered to include only the methods that are valid for running a `geoNear` command in MongoDB (fetching entities as a `GeoResult` within `GeoResults`), as the following example shows:

====
[source,java]
----
GeoResults<Jedi> results = mongoOps.query(SWCharacter.class)
  .as(Jedi.class)
  .near(alderaan) // NearQuery.near(-73.9667, 40.78).maxDis…
  .all();
----
====

[[mongo.query.kotlin-support]]
=== Type-safe Queries for Kotlin

Kotlin embraces domain-specific language creation through its language syntax and its extension system.
Spring Data MongoDB ships with a Kotlin Extension for `Criteria` using https://kotlinlang.org/docs/reference/reflection.html#property-references[Kotlin property references] to build type-safe queries.
Queries using this extension are typically benefit from improved readability.
Most keywords on `Criteria` have a matching Kotlin extension, such as `inValues` and `regex`.

Consider the following example explaining Type-safe Queries:

====
[source,kotlin]
----
import org.springframework.data.mongodb.core.query.*

mongoOperations.find<Book>(
  Query(Book::title isEqualTo "Moby-Dick")               <1>
)

mongoOperations.find<Book>(
  Query(titlePredicate = Book::title exists true)
)

mongoOperations.find<Book>(
  Query(
    Criteria().andOperator(
      Book::price gt 5,
      Book::price lt 10
    ))
)

// Binary operators
mongoOperations.find<BinaryMessage>(
  Query(BinaryMessage::payload bits { allClear(0b101) }) <2>
)

// Nested Properties (i.e. refer to "book.author")
mongoOperations.find<Book>(
  Query(Book::author / Author::name regex "^H")          <3>
)
----
<1> `isEqualTo()` is an infix extension function with receiver type `KProperty<T>` that returns `Criteria`.
<2> For bitwise operators, pass a lambda argument where you call one of the methods of `Criteria.BitwiseCriteriaOperators`.
<3> To construct nested properties, use the `/` character (overloaded operator `div`).
====

[[mongo.query.additional-query-options]]
=== Additional Query Options

MongoDB offers various ways of applying meta information, like a comment or a batch size, to a query.Using the `Query` API
directly there are several methods for those options.

====
[source,java]
----
Query query = query(where("firstname").is("luke"))
    .comment("find luke")         <1>
    .batchSize(100)                                 <2>
----
<1> The comment propagated to the MongoDB profile log.
<2> The number of documents to return in each response batch.
====

On the repository level the `@Meta` annotation provides means to add query options in a declarative way.

====
[source,java]
----
@Meta(comment = "find luke", batchSize = 100, flags = { SLAVE_OK })
List<Person> findByFirstname(String firstname);
----
====

include::../{spring-data-commons-docs}/query-by-example.adoc[leveloffset=+1]
include::query-by-example.adoc[leveloffset=+1]

[[mongo.query.count]]
== Counting Documents

In pre-3.x versions of SpringData MongoDB the count operation used MongoDBs internal collection statistics.
With the introduction of <<mongo.transactions>> this was no longer possible because statistics would not correctly reflect potential changes during a transaction requiring an aggregation-based count approach.
So in version 2.x `MongoOperations.count()` would use the collection statistics if no transaction was in progress, and the aggregation variant if so.

As of Spring Data MongoDB 3.x any `count` operation uses regardless the existence of filter criteria the aggregation-based count approach via MongoDBs `countDocuments`.
If the application is fine with the limitations of working upon collection statistics `MongoOperations.estimatedCount()` offers an alternative.

[NOTE]
====
MongoDBs native `countDocuments` method and the `$match` aggregation, do not support `$near` and `$nearSphere` but require `$geoWithin` along with `$center` or `$centerSphere` which does not support `$minDistance` (see https://jira.mongodb.org/browse/SERVER-37043).

Therefore a given `Query` will be rewritten for `count` operations using `Reactive`-/`MongoTemplate` to bypass the issue like shown below.

[source,javascript]
----
{ location : { $near : [-73.99171, 40.738868], $maxDistance : 1.1 } } <1>
{ location : { $geoWithin : { $center: [ [-73.99171, 40.738868], 1.1] } } } <2>

{ location : { $near : [-73.99171, 40.738868], $minDistance : 0.1, $maxDistance : 1.1 } } <3>
{$and :[ { $nor :[ { location :{ $geoWithin :{ $center :[ [-73.99171, 40.738868 ], 0.01] } } } ]}, { location :{ $geoWithin :{ $center :[ [-73.99171, 40.738868 ], 1.1] } } } ] } <4>
----
<1> Count source query using `$near`.
<2> Rewritten query now using `$geoWithin` with `$center`.
<3> Count source query using `$near` with `$minDistance` and `$maxDistance`.
<4> Rewritten query now a combination of `$nor` `$geowithin` critierias to work around unsupported `$minDistance`.
====

[[mongo.mapreduce]]
== Map-Reduce Operations

You can query MongoDB by using Map-Reduce, which is useful for batch processing, for data aggregation, and for when the query language does not fulfill your needs.

Spring provides integration with MongoDB's Map-Reduce by providing methods on `MongoOperations` to simplify the creation and running of Map-Reduce operations.It can convert the results of a Map-Reduce operation to a POJO and integrates with Spring's https://docs.spring.io/spring/docs/{springVersion}/spring-framework-reference/core.html#resources[Resource abstraction].This lets you place your JavaScript files on the file system, classpath, HTTP server, or any other Spring Resource implementation and then reference the JavaScript resources through an easy URI style syntax -- for example, `classpath:reduce.js;`.Externalizing JavaScript code in files is often preferable to embedding them as Java strings in your code.Note that you can still pass JavaScript code as Java strings if you prefer.

[[mongo.mapreduce.example]]
=== Example Usage

To understand how to perform Map-Reduce operations, we use an example from the book, _MongoDB - The Definitive Guide_ footnote:[Kristina Chodorow. _MongoDB - The Definitive Guide_. O'Reilly Media, 2013].In this example, we create three documents that have the values [a,b], [b,c], and [c,d], respectively.The values in each document are associated with the key, 'x', as the following example shows (assume these documents are in a collection named `jmr1`):

[source]
----
{ "_id" : ObjectId("4e5ff893c0277826074ec533"), "x" : [ "a", "b" ] }
{ "_id" : ObjectId("4e5ff893c0277826074ec534"), "x" : [ "b", "c" ] }
{ "_id" : ObjectId("4e5ff893c0277826074ec535"), "x" : [ "c", "d" ] }
----

The following map function counts the occurrence of each letter in the array for each document:

[source,java]
----
function () {
    for (var i = 0; i < this.x.length; i++) {
        emit(this.x[i], 1);
    }
}
----

The follwing reduce function sums up the occurrence of each letter across all the documents:

[source,java]
----
function (key, values) {
    var sum = 0;
    for (var i = 0; i < values.length; i++)
        sum += values[i];
    return sum;
}
----

Running the preceding functions result in the following collection:

[source]
----
{ "_id" : "a", "value" : 1 }
{ "_id" : "b", "value" : 2 }
{ "_id" : "c", "value" : 2 }
{ "_id" : "d", "value" : 1 }
----

Assuming that the map and reduce functions are located in `map.js` and `reduce.js` and bundled in your jar so they are available on the classpath, you can run a Map-Reduce operation as follows:

[source,java]
----
MapReduceResults<ValueObject> results = mongoOperations.mapReduce("jmr1", "classpath:map.js", "classpath:reduce.js", ValueObject.class);
for (ValueObject valueObject : results) {
  System.out.println(valueObject);
}
----

The preceding exmaple produces the following output:

[source]
----
ValueObject [id=a, value=1.0]
ValueObject [id=b, value=2.0]
ValueObject [id=c, value=2.0]
ValueObject [id=d, value=1.0]
----

The `MapReduceResults` class implements `Iterable` and provides access to the raw output and timing and count statistics.The following listing shows the `ValueObject` class:

[source,java]
----
public class ValueObject {

  private String id;
  private float value;

  public String getId() {
    return id;
  }

  public float getValue() {
    return value;
  }

  public void setValue(float value) {
    this.value = value;
  }

  @Override
  public String toString() {
    return "ValueObject [id=" + id + ", value=" + value + "]";
  }
}
----

By default, the output type of `INLINE` is used so that you need not specify an output collection.To specify additional Map-Reduce options, use an overloaded method that takes an additional `MapReduceOptions` argument.The class `MapReduceOptions` has a fluent API, so adding additional options can be done in a compact syntax.The following example sets the output collection to `jmr1_out` (note that setting only the output collection assumes a default output type of `REPLACE`):

[source,java]
----
MapReduceResults<ValueObject> results = mongoOperations.mapReduce("jmr1", "classpath:map.js", "classpath:reduce.js",
                                                                     new MapReduceOptions().outputCollection("jmr1_out"), ValueObject.class);
----

There is also a static import (`import static org.springframework.data.mongodb.core.mapreduce.MapReduceOptions.options;`) that can be used to make the syntax slightly more compact, as the following example shows:

[source,java]
----
MapReduceResults<ValueObject> results = mongoOperations.mapReduce("jmr1", "classpath:map.js", "classpath:reduce.js",
                                                                     options().outputCollection("jmr1_out"), ValueObject.class);
----

You can also specify a query to reduce the set of data that is fed into the Map-Reduce operation.The following example removes the document that contains [a,b] from consideration for Map-Reduce operations:

[source,java]
----
Query query = new Query(where("x").ne(new String[] { "a", "b" }));
MapReduceResults<ValueObject> results = mongoOperations.mapReduce(query, "jmr1", "classpath:map.js", "classpath:reduce.js",
                                                                     options().outputCollection("jmr1_out"), ValueObject.class);
----

Note that you can specify additional limit and sort values on the query, but you cannot skip values.

[[mongo.server-side-scripts]]
== Script Operations

[WARNING]
====
https://docs.mongodb.com/master/release-notes/4.2-compatibility/[MongoDB 4.2] removed support for the `eval` command used
by `ScriptOperations`. +
There is no replacement for the removed functionality.
====

MongoDB allows running JavaScript functions on the server by either directly sending the script or calling a stored one. `ScriptOperations` can be accessed through `MongoTemplate` and provides basic abstraction for `JavaScript` usage. The following example shows how to us the `ScriptOperations` class:

====
[source,java]
----
ScriptOperations scriptOps = template.scriptOps();

ExecutableMongoScript echoScript = new ExecutableMongoScript("function(x) { return x; }");
scriptOps.execute(echoScript, "directly execute script");     <1>

scriptOps.register(new NamedMongoScript("echo", echoScript)); <2>
scriptOps.call("echo", "execute script via name");            <3>
----
<1> Run the script directly without storing the function on server side.
<2> Store the script using 'echo' as its name. The given name identifies the script and allows calling it later.
<3> Run the script with name 'echo' using the provided parameters.
====

[[mongo.group]]
== Group Operations

As an alternative to using Map-Reduce to perform data aggregation, you can use the https://www.mongodb.org/display/DOCS/Aggregation#Aggregation-Group[`group` operation] which feels similar to using SQL's group by query style, so it may feel more approachable vs. using Map-Reduce. Using the group operations does have some limitations, for example it is not supported in a shared environment and it returns the full result set in a single BSON object, so the result should be small, less than 10,000 keys.

Spring provides integration with MongoDB's group operation by providing methods on MongoOperations to simplify the creation and running of group operations. It can convert the results of the group operation to a POJO and also integrates with Spring's https://docs.spring.io/spring/docs/{springVersion}/spring-framework-reference/core.html#resources[Resource abstraction] abstraction. This will let you place your JavaScript files on the file system, classpath, http server or any other Spring Resource implementation and then reference the JavaScript resources via an easy URI style syntax, e.g. 'classpath:reduce.js;. Externalizing JavaScript code in files if often preferable to embedding them as Java strings in your code. Note that you can still pass JavaScript code as Java strings if you prefer.

[[mongo.group.example]]
=== Example Usage

In order to understand how group operations work the following example is used, which is somewhat artificial. For a more realistic example consult the book 'MongoDB - The definitive guide'. A collection named `group_test_collection` created with the following rows.

[source]
----
{ "_id" : ObjectId("4ec1d25d41421e2015da64f1"), "x" : 1 }
{ "_id" : ObjectId("4ec1d25d41421e2015da64f2"), "x" : 1 }
{ "_id" : ObjectId("4ec1d25d41421e2015da64f3"), "x" : 2 }
{ "_id" : ObjectId("4ec1d25d41421e2015da64f4"), "x" : 3 }
{ "_id" : ObjectId("4ec1d25d41421e2015da64f5"), "x" : 3 }
{ "_id" : ObjectId("4ec1d25d41421e2015da64f6"), "x" : 3 }
----

We would like to group by the only field in each row, the `x` field and aggregate the number of times each specific value of `x` occurs. To do this we need to create an initial document that contains our count variable and also a reduce function which will increment it each time it is encountered. The Java code to run the group operation is shown below

[source,java]
----
GroupByResults<XObject> results = mongoTemplate.group("group_test_collection",
                                                      GroupBy.key("x").initialDocument("{ count: 0 }").reduceFunction("function(doc, prev) { prev.count += 1 }"),
                                                      XObject.class);
----

The first argument is the name of the collection to run the group operation over, the second is a fluent API that specifies properties of the group operation via a `GroupBy` class. In this example we are using just the `intialDocument` and `reduceFunction` methods. You can also specify a key-function, as well as a finalizer as part of the fluent API. If you have multiple keys to group by, you can pass in a comma separated list of keys.

The raw results of the group operation is a JSON document that looks like this

[source]
----
{
  "retval" : [ { "x" : 1.0 , "count" : 2.0} ,
               { "x" : 2.0 , "count" : 1.0} ,
               { "x" : 3.0 , "count" : 3.0} ] ,
  "count" : 6.0 ,
  "keys" : 3 ,
  "ok" : 1.0
}
----

The document under the "retval" field is mapped onto the third argument in the group method, in this case XObject which is shown below.

[source,java]
----
public class XObject {

  private float x;

  private float count;


  public float getX() {
    return x;
  }

  public void setX(float x) {
    this.x = x;
  }

  public float getCount() {
    return count;
  }

  public void setCount(float count) {
    this.count = count;
  }

  @Override
  public String toString() {
    return "XObject [x=" + x + " count = " + count + "]";
  }
}
----

You can also obtain the raw result as a `Document` by calling the method `getRawResults` on the `GroupByResults` class.

There is an additional method overload of the group method on `MongoOperations` which lets you specify a `Criteria` object for selecting a subset of the rows. An example which uses a `Criteria` object, with some syntax sugar using static imports, as well as referencing a key-function and reduce function javascript files via a Spring Resource string is shown below.

[source]
----
import static org.springframework.data.mongodb.core.mapreduce.GroupBy.keyFunction;
import static org.springframework.data.mongodb.core.query.Criteria.where;

GroupByResults<XObject> results = mongoTemplate.group(where("x").gt(0),
                                        "group_test_collection",
                                        keyFunction("classpath:keyFunction.js").initialDocument("{ count: 0 }").reduceFunction("classpath:groupReduce.js"), XObject.class);
----

[[mongo.aggregation]]
== Aggregation Framework Support

Spring Data MongoDB provides support for the Aggregation Framework introduced to MongoDB in version 2.2.

For further information, see the full https://docs.mongodb.org/manual/aggregation/[reference documentation] of the aggregation framework and other data aggregation tools for MongoDB.

[[mongo.aggregation.basic-concepts]]
=== Basic Concepts

The Aggregation Framework support in Spring Data MongoDB is based on the following key abstractions: `Aggregation`, `AggregationOperation`, and `AggregationResults`.

* `Aggregation`
+
An `Aggregation` represents a MongoDB `aggregate` operation and holds the description of the aggregation pipeline instructions. Aggregations are created by invoking the appropriate `newAggregation(…)` static factory method of the `Aggregation` class, which takes a list of `AggregateOperation` and an optional input class.
+
The actual aggregate operation is run by the `aggregate` method of the `MongoTemplate`, which takes the desired output class as a parameter.
+
* `TypedAggregation`
+
A `TypedAggregation`, just like an `Aggregation`, holds the instructions of the aggregation pipeline and a reference to the input type, that is used for mapping domain properties to actual document fields.
+
At runtime, field references get checked against the given input type, considering potential `@Field` annotations and raising errors when referencing nonexistent properties.
+
* `AggregationOperation`
+
An `AggregationOperation` represents a MongoDB aggregation pipeline operation and describes the processing that should be performed in this aggregation step. Although you could manually create an `AggregationOperation`, we recommend using the static factory methods provided by the `Aggregate` class to construct an `AggregateOperation`.
+
* `AggregationResults`
+
`AggregationResults` is the container for the result of an aggregate operation. It provides access to the raw aggregation result, in the form of a `Document` to the mapped objects and other information about the aggregation.
+
The following listing shows the canonical example for using the Spring Data MongoDB support for the MongoDB Aggregation Framework:
+
[source,java]
----
import static org.springframework.data.mongodb.core.aggregation.Aggregation.*;

Aggregation agg = newAggregation(
    pipelineOP1(),
    pipelineOP2(),
    pipelineOPn()
);

AggregationResults<OutputType> results = mongoTemplate.aggregate(agg, "INPUT_COLLECTION_NAME", OutputType.class);
List<OutputType> mappedResult = results.getMappedResults();
----

Note that, if you provide an input class as the first parameter to the `newAggregation` method, the `MongoTemplate` derives the name of the input collection from this class. Otherwise, if you do not not specify an input class, you must provide the name of the input collection explicitly. If both an input class and an input collection are provided, the latter takes precedence.

[[mongo.aggregation.supported-aggregation-operations]]
=== Supported Aggregation Operations

The MongoDB Aggregation Framework provides the following types of aggregation operations:

* Pipeline Aggregation Operators
* Group Aggregation Operators
* Boolean Aggregation Operators
* Comparison Aggregation Operators
* Arithmetic Aggregation Operators
* String Aggregation Operators
* Date Aggregation Operators
* Array Aggregation Operators
* Conditional Aggregation Operators
* Lookup Aggregation Operators
* Convert Aggregation Operators
* Object Aggregation Operators
* Script Aggregation Operators

At the time of this writing, we provide support for the following Aggregation Operations in Spring Data MongoDB:

.Aggregation Operations currently supported by Spring Data MongoDB
[cols="2*"]
|===
| Pipeline Aggregation Operators
| `bucket`, `bucketAuto`, `count`, `facet`, `geoNear`, `graphLookup`, `group`, `limit`, `lookup`, `match`, `project`, `replaceRoot`, `skip`, `sort`, `unwind`

| Set Aggregation Operators
| `setEquals`, `setIntersection`, `setUnion`, `setDifference`, `setIsSubset`, `anyElementTrue`, `allElementsTrue`

| Group Aggregation Operators
| `addToSet`, `first`, `last`, `max`, `min`, `avg`, `push`, `sum`, `(*count)`, `stdDevPop`, `stdDevSamp`

| Arithmetic Aggregation Operators
| `abs`, `add` (*via `plus`), `ceil`, `divide`, `exp`, `floor`, `ln`, `log`, `log10`, `mod`, `multiply`, `pow`, `round`, `sqrt`, `subtract` (*via `minus`), `trunc`

| String Aggregation Operators
| `concat`, `substr`, `toLower`, `toUpper`, `stcasecmp`, `indexOfBytes`, `indexOfCP`, `split`, `strLenBytes`, `strLenCP`, `substrCP`, `trim`, `ltrim`, `rtim`

| Comparison Aggregation Operators
| `eq` (*via: `is`), `gt`, `gte`, `lt`, `lte`, `ne`

| Array Aggregation Operators
| `arrayElementAt`, `arrayToObject`, `concatArrays`, `filter`, `in`, `indexOfArray`, `isArray`, `range`, `reverseArray`, `reduce`, `size`, `slice`, `zip`

| Literal Operators
| `literal`

| Date Aggregation Operators
| `dayOfYear`, `dayOfMonth`, `dayOfWeek`, `year`, `month`, `week`, `hour`, `minute`, `second`, `millisecond`, `dateToString`, `dateFromString`, `dateFromParts`, `dateToParts`, `isoDayOfWeek`, `isoWeek`, `isoWeekYear`

| Variable Operators
| `map`

| Conditional Aggregation Operators
| `cond`, `ifNull`, `switch`

| Type Aggregation Operators
| `type`

| Convert Aggregation Operators
| `convert`, `toBool`, `toDate`, `toDecimal`, `toDouble`, `toInt`, `toLong`, `toObjectId`, `toString`

| Object Aggregation Operators
| `objectToArray`, `mergeObjects`

| Script Aggregation Operators
| `function`, `accumulator`
|===

* The operation is mapped or added by Spring Data MongoDB.

Note that the aggregation operations not listed here are currently not supported by Spring Data MongoDB. Comparison aggregation operators are expressed as `Criteria` expressions.

[[mongo.aggregation.projection]]
=== Projection Expressions

Projection expressions are used to define the fields that are the outcome of a particular aggregation step. Projection expressions can be defined through the `project` method of the `Aggregation` class, either by passing a list of `String` objects or an aggregation framework `Fields` object. The projection can be extended with additional fields through a fluent API by using the `and(String)` method and aliased by using the `as(String)` method.
Note that you can also define fields with aliases by using the `Fields.field` static factory method of the aggregation framework, which you can then use to construct a new `Fields` instance. References to projected fields in later aggregation stages are valid only for the field names of included fields or their aliases (including newly defined fields and their aliases). Fields not included in the projection cannot be referenced in later aggregation stages. The following listings show examples of projection expression:

.Projection expression examples
====
[source,java]
----
// generates {$project: {name: 1, netPrice: 1}}
project("name", "netPrice")

// generates {$project: {thing1: $thing2}}
project().and("thing1").as("thing2")

// generates {$project: {a: 1, b: 1, thing2: $thing1}}
project("a","b").and("thing1").as("thing2")
----
====

.Multi-Stage Aggregation using Projection and Sorting
====
[source,java]
----
// generates {$project: {name: 1, netPrice: 1}}, {$sort: {name: 1}}
project("name", "netPrice"), sort(ASC, "name")

// generates {$project: {name: $firstname}}, {$sort: {name: 1}}
project().and("firstname").as("name"), sort(ASC, "name")

// does not work
project().and("firstname").as("name"), sort(ASC, "firstname")
----
====

More examples for project operations can be found in the `AggregationTests` class. Note that further details regarding the projection expressions can be found in the https://docs.mongodb.org/manual/reference/operator/aggregation/project/#pipe._S_project[corresponding section] of the MongoDB Aggregation Framework reference documentation.

[[mongo.aggregation.facet]]
=== Faceted Classification

As of Version 3.4, MongoDB supports faceted classification by using the Aggregation Framework. A faceted classification uses semantic categories (either general or subject-specific) that are combined to create the full classification entry. Documents flowing through the aggregation pipeline are classified into buckets. A multi-faceted classification enables various aggregations on the same set of input documents, without needing to retrieve the input documents multiple times.

==== Buckets

Bucket operations categorize incoming documents into groups, called buckets, based on a specified expression and bucket boundaries. Bucket operations require a grouping field or a grouping expression. You can define them by using the `bucket()` and `bucketAuto()` methods of the `Aggregate` class. `BucketOperation` and `BucketAutoOperation` can expose accumulations based on aggregation expressions for input documents. You can extend the bucket operation with additional parameters through a fluent API by using the `with…()` methods and the `andOutput(String)` method. You can alias the operation by using the `as(String)` method. Each bucket is represented as a document in the output.

`BucketOperation` takes a defined set of boundaries to group incoming documents into these categories. Boundaries are required to be sorted. The following listing shows some examples of bucket operations:

.Bucket operation examples
====
[source,java]
----
// generates {$bucket: {groupBy: $price, boundaries: [0, 100, 400]}}
bucket("price").withBoundaries(0, 100, 400);

// generates {$bucket: {groupBy: $price, default: "Other" boundaries: [0, 100]}}
bucket("price").withBoundaries(0, 100).withDefault("Other");

// generates {$bucket: {groupBy: $price, boundaries: [0, 100], output: { count: { $sum: 1}}}}
bucket("price").withBoundaries(0, 100).andOutputCount().as("count");

// generates {$bucket: {groupBy: $price, boundaries: [0, 100], 5, output: { titles: { $push: "$title"}}}
bucket("price").withBoundaries(0, 100).andOutput("title").push().as("titles");
----
====

`BucketAutoOperation` determines boundaries in an attempt to evenly distribute documents into a specified number of buckets. `BucketAutoOperation` optionally takes a granularity value that specifies the https://en.wikipedia.org/wiki/Preferred_number[preferred number] series to use to ensure that the calculated boundary edges end on preferred round numbers or on powers of 10. The following listing shows examples of bucket operations:

.Bucket operation examples
====
[source,java]
----
// generates {$bucketAuto: {groupBy: $price, buckets: 5}}
bucketAuto("price", 5)

// generates {$bucketAuto: {groupBy: $price, buckets: 5, granularity: "E24"}}
bucketAuto("price", 5).withGranularity(Granularities.E24).withDefault("Other");

// generates {$bucketAuto: {groupBy: $price, buckets: 5, output: { titles: { $push: "$title"}}}
bucketAuto("price", 5).andOutput("title").push().as("titles");
----
====

To create output fields in buckets, bucket operations can use `AggregationExpression` through `andOutput()` and <<mongo.aggregation.projection.expressions, SpEL expressions>> through `andOutputExpression()`.

Note that further details regarding bucket expressions can be found in the https://docs.mongodb.org/manual/reference/operator/aggregation/bucket/[`$bucket` section] and
https://docs.mongodb.org/manual/reference/operator/aggregation/bucketAuto/[`$bucketAuto` section] of the MongoDB Aggregation Framework reference documentation.

==== Multi-faceted Aggregation

Multiple aggregation pipelines can be used to create multi-faceted aggregations that characterize data across multiple dimensions (or facets) within a single aggregation stage. Multi-faceted aggregations provide multiple filters and categorizations to guide data browsing and analysis. A common implementation of faceting is how many online retailers provide ways to narrow down search results by applying filters on product price, manufacturer, size, and other factors.

You can define a `FacetOperation` by using the `facet()` method of the `Aggregation` class. You can customize it with multiple aggregation pipelines by using the `and()` method. Each sub-pipeline has its own field in the output document where its results are stored as an array of documents.

Sub-pipelines can project and filter input documents prior to grouping. Common use cases include extraction of date parts or calculations before categorization. The following listing shows facet operation examples:

.Facet operation examples
====
[source,java]
----
// generates {$facet: {categorizedByPrice: [ { $match: { price: {$exists : true}}}, { $bucketAuto: {groupBy: $price, buckets: 5}}]}}
facet(match(Criteria.where("price").exists(true)), bucketAuto("price", 5)).as("categorizedByPrice"))

// generates {$facet: {categorizedByCountry: [ { $match: { country: {$exists : true}}}, { $sortByCount: "$country"}]}}
facet(match(Criteria.where("country").exists(true)), sortByCount("country")).as("categorizedByCountry"))

// generates {$facet: {categorizedByYear: [
//     { $project: { title: 1, publicationYear: { $year: "publicationDate"}}},
//     { $bucketAuto: {groupBy: $price, buckets: 5, output: { titles: {$push:"$title"}}}
// ]}}
facet(project("title").and("publicationDate").extractYear().as("publicationYear"),
      bucketAuto("publicationYear", 5).andOutput("title").push().as("titles"))
  .as("categorizedByYear"))
----
====

Note that further details regarding facet operation can be found in the https://docs.mongodb.org/manual/reference/operator/aggregation/facet/[`$facet` section] of the MongoDB Aggregation Framework reference documentation.

[[mongo.aggregation.sort-by-count]]
==== Sort By Count

Sort by count operations group incoming documents based on the value of a specified expression, compute the count of documents in each distinct group, and sort the results by count. It offers a handy shortcut to apply sorting when using <<mongo.aggregation.facet>>. Sort by count operations require a grouping field or grouping expression. The following listing shows a sort by count example:

.Sort by count example
====
[source,java]
----
// generates { $sortByCount: "$country" }
sortByCount("country");
----
====

A sort by count operation is equivalent to the following BSON (Binary JSON):

----
{ $group: { _id: <expression>, count: { $sum: 1 } } },
{ $sort: { count: -1 } }
----

[[mongo.aggregation.projection.expressions]]
==== Spring Expression Support in Projection Expressions

We support the use of SpEL expressions in projection expressions through the `andExpression` method of the `ProjectionOperation` and `BucketOperation` classes. This feature lets you define the desired expression as a SpEL expression. On running a query, the SpEL expression is translated into a corresponding MongoDB projection expression part. This arrangement makes it much easier to express complex calculations.

===== Complex Calculations with SpEL expressions

Consider the following SpEL expression:

[source,java]
----
1 + (q + 1) / (q - 1)
----

The preceding expression is translated into the following projection expression part:

[source,javascript]
----
{ "$add" : [ 1, {
    "$divide" : [ {
        "$add":["$q", 1]}, {
        "$subtract":[ "$q", 1]}
    ]
}]}
----

You can see examples in more context in <<mongo.aggregation.examples.example5>> and <<mongo.aggregation.examples.example6>>. You can find more usage examples for supported SpEL expression constructs in `SpelExpressionTransformerUnitTests`. The following table shows the SpEL transformations supported by Spring Data MongoDB:

.Supported SpEL transformations
[%header,cols="2"]
|===
| SpEL Expression
| Mongo Expression Part
| a == b
| { $eq : [$a, $b] }
| a != b
| { $ne : [$a , $b] }
| a > b
| { $gt : [$a, $b] }
| a >= b
| { $gte : [$a, $b] }
| a < b
| { $lt : [$a, $b] }
| a <= b
| { $lte : [$a, $b] }
| a + b
| { $add : [$a, $b] }
| a - b
| { $subtract : [$a, $b] }
| a * b
| { $multiply : [$a, $b] }
| a / b
| { $divide : [$a, $b] }
| a^b
| { $pow : [$a, $b] }
| a % b
| { $mod : [$a, $b] }
| a && b
| { $and : [$a, $b] }
| a \|\| b
| { $or : [$a, $b] }
| !a
| { $not : [$a] }
|===

In addition to the transformations shown in the preceding table, you can use standard SpEL operations such as `new` to (for example) create arrays and reference expressions through their names (followed by the arguments to use in brackets). The following example shows how to create an array in this fashion:

[source,java]
----
// { $setEquals : [$a, [5, 8, 13] ] }
.andExpression("setEquals(a, new int[]{5, 8, 13})");
----

[[mongo.aggregation.examples]]
==== Aggregation Framework Examples

The examples in this section demonstrate the usage patterns for the MongoDB Aggregation Framework with Spring Data MongoDB.

[[mongo.aggregation.examples.example1]]
===== Aggregation Framework Example 1

In this introductory example, we want to aggregate a list of tags to get the occurrence count of a particular tag from a MongoDB collection (called `tags`) sorted by the occurrence count in descending order. This example demonstrates the usage of grouping, sorting, projections (selection), and unwinding (result splitting).

[source,java]
----
class TagCount {
 String tag;
 int n;
}
----

[source,java]
----
import static org.springframework.data.mongodb.core.aggregation.Aggregation.*;

Aggregation agg = newAggregation(
    project("tags"),
    unwind("tags"),
    group("tags").count().as("n"),
    project("n").and("tag").previousOperation(),
    sort(DESC, "n")
);

AggregationResults<TagCount> results = mongoTemplate.aggregate(agg, "tags", TagCount.class);
List<TagCount> tagCount = results.getMappedResults();
----

The preceding listing uses the following algorithm:

. Create a new aggregation by using the `newAggregation` static factory method, to which we pass a list of aggregation operations. These aggregate operations define the aggregation pipeline of our `Aggregation`.
. Use the `project` operation to select the `tags` field (which is an array of strings) from the input collection.
. Use the `unwind` operation to generate a new document for each tag within the `tags` array.
. Use the `group` operation to define a group for each `tags` value for which we aggregate the occurrence count (by using the `count` aggregation operator and collecting the result in a new field called `n`).
. Select the `n` field and create an alias for the ID field generated from the previous group operation (hence the call to `previousOperation()`) with a name of `tag`.
. Use the `sort` operation to sort the resulting list of tags by their occurrence count in descending order.
. Call the `aggregate` method on `MongoTemplate` to let MongoDB perform the actual aggregation operation, with the created `Aggregation` as an argument.

Note that the input collection is explicitly specified as the `tags` parameter to the `aggregate` Method. If the name of the input collection is not specified explicitly, it is derived from the input class passed as the first parameter to the `newAggreation` method.

[[mongo.aggregation.examples.example2]]
===== Aggregation Framework Example 2

This example is based on the https://docs.mongodb.org/manual/tutorial/aggregation-examples/#largest-and-smallest-cities-by-state[Largest and Smallest Cities by State] example from the MongoDB Aggregation Framework documentation. We added additional sorting to produce stable results with different MongoDB versions. Here we want to return the smallest and largest cities by population for each state by using the aggregation framework. This example demonstrates grouping, sorting, and projections (selection).

[source,java]
----
class ZipInfo {
   String id;
   String city;
   String state;
   @Field("pop") int population;
   @Field("loc") double[] location;
}

class City {
   String name;
   int population;
}

class ZipInfoStats {
   String id;
   String state;
   City biggestCity;
   City smallestCity;
}
----

[source,java]
----
import static org.springframework.data.mongodb.core.aggregation.Aggregation.*;

TypedAggregation<ZipInfo> aggregation = newAggregation(ZipInfo.class,
    group("state", "city")
       .sum("population").as("pop"),
    sort(ASC, "pop", "state", "city"),
    group("state")
       .last("city").as("biggestCity")
       .last("pop").as("biggestPop")
       .first("city").as("smallestCity")
       .first("pop").as("smallestPop"),
    project()
       .and("state").previousOperation()
       .and("biggestCity")
          .nested(bind("name", "biggestCity").and("population", "biggestPop"))
       .and("smallestCity")
          .nested(bind("name", "smallestCity").and("population", "smallestPop")),
    sort(ASC, "state")
);

AggregationResults<ZipInfoStats> result = mongoTemplate.aggregate(aggregation, ZipInfoStats.class);
ZipInfoStats firstZipInfoStats = result.getMappedResults().get(0);
----

Note that the `ZipInfo` class maps the structure of the given input-collection. The `ZipInfoStats` class defines the structure in the desired output format.

The preceding listings use the following algorithm:

. Use the `group` operation to define a group from the input-collection. The grouping criteria is the combination of the `state` and `city` fields, which forms the ID structure of the group. We aggregate the value of the `population` property from the grouped elements by using the `sum` operator and save the result in the `pop` field.
. Use the `sort` operation to sort the intermediate-result by the `pop`, `state` and `city` fields, in ascending order, such that the smallest city is at the top and the biggest city is at the bottom of the result. Note that the sorting on `state` and `city` is implicitly performed against the group ID fields (which Spring Data MongoDB handled).
. Use a `group` operation again to group the intermediate result by `state`. Note that `state` again implicitly references a group ID field. We select the name and the population count of the biggest and smallest city with calls to the `last(…)` and `first(...)` operators, respectively, in the `project` operation.
. Select the `state` field from the previous `group` operation. Note that `state` again implicitly references a group ID field. Because we do not want an implicitly generated ID to appear, we exclude the ID from the previous operation by using `and(previousOperation()).exclude()`. Because we want to populate the nested `City` structures in our output class, we have to emit appropriate sub-documents by using the nested method.
. Sort the resulting list of `StateStats` by their state name in ascending order in the `sort` operation.

Note that we derive the name of the input collection from the `ZipInfo` class passed as the first parameter to the `newAggregation` method.

[[mongo.aggregation.examples.example3]]
===== Aggregation Framework Example 3

This example is based on the https://docs.mongodb.org/manual/tutorial/aggregation-examples/#states-with-populations-over-10-million[States with Populations Over 10 Million] example from the MongoDB Aggregation Framework documentation. We added additional sorting to produce stable results with different MongoDB versions. Here we want to return all states with a population greater than 10 million, using the aggregation framework. This example demonstrates grouping, sorting, and matching (filtering).

[source,java]
----
class StateStats {
   @Id String id;
   String state;
   @Field("totalPop") int totalPopulation;
}
----

[source,java]
----
import static org.springframework.data.mongodb.core.aggregation.Aggregation.*;

TypedAggregation<ZipInfo> agg = newAggregation(ZipInfo.class,
    group("state").sum("population").as("totalPop"),
    sort(ASC, previousOperation(), "totalPop"),
    match(where("totalPop").gte(10 * 1000 * 1000))
);

AggregationResults<StateStats> result = mongoTemplate.aggregate(agg, StateStats.class);
List<StateStats> stateStatsList = result.getMappedResults();
----

The preceding listings use the following algorithm:

. Group the input collection by the `state` field and calculate the sum of the `population` field and store the result in the new field `"totalPop"`.
. Sort the intermediate result by the id-reference of the previous group operation in addition to the `"totalPop"` field in ascending order.
. Filter the intermediate result by using a `match` operation which accepts a `Criteria` query as an argument.

Note that we derive the name of the input collection from the `ZipInfo` class passed as first parameter to the `newAggregation` method.

[[mongo.aggregation.examples.example4]]
===== Aggregation Framework Example 4

This example demonstrates the use of simple arithmetic operations in the projection operation.

[source,java]
----
class Product {
    String id;
    String name;
    double netPrice;
    int spaceUnits;
}
----

[source,java]
----
import static org.springframework.data.mongodb.core.aggregation.Aggregation.*;

TypedAggregation<Product> agg = newAggregation(Product.class,
    project("name", "netPrice")
        .and("netPrice").plus(1).as("netPricePlus1")
        .and("netPrice").minus(1).as("netPriceMinus1")
        .and("netPrice").multiply(1.19).as("grossPrice")
        .and("netPrice").divide(2).as("netPriceDiv2")
        .and("spaceUnits").mod(2).as("spaceUnitsMod2")
);

AggregationResults<Document> result = mongoTemplate.aggregate(agg, Document.class);
List<Document> resultList = result.getMappedResults();
----

Note that we derive the name of the input collection from the `Product` class passed as first parameter to the `newAggregation` method.

[[mongo.aggregation.examples.example5]]
===== Aggregation Framework Example 5

This example demonstrates the use of simple arithmetic operations derived from SpEL Expressions in the projection operation.

[source,java]
----
class Product {
    String id;
    String name;
    double netPrice;
    int spaceUnits;
}
----

[source,java]
----
import static org.springframework.data.mongodb.core.aggregation.Aggregation.*;

TypedAggregation<Product> agg = newAggregation(Product.class,
    project("name", "netPrice")
        .andExpression("netPrice + 1").as("netPricePlus1")
        .andExpression("netPrice - 1").as("netPriceMinus1")
        .andExpression("netPrice / 2").as("netPriceDiv2")
        .andExpression("netPrice * 1.19").as("grossPrice")
        .andExpression("spaceUnits % 2").as("spaceUnitsMod2")
        .andExpression("(netPrice * 0.8  + 1.2) * 1.19").as("grossPriceIncludingDiscountAndCharge")

);

AggregationResults<Document> result = mongoTemplate.aggregate(agg, Document.class);
List<Document> resultList = result.getMappedResults();
----

[[mongo.aggregation.examples.example6]]
===== Aggregation Framework Example 6

This example demonstrates the use of complex arithmetic operations derived from SpEL Expressions in the projection operation.

Note: The additional parameters passed to the `addExpression` method can be referenced with indexer expressions according to their position. In this example, we reference the first parameter of the parameters array with `[0]`. When the SpEL expression is transformed into a MongoDB aggregation framework expression, external parameter expressions are replaced with their respective values.

[source,java]
----
class Product {
    String id;
    String name;
    double netPrice;
    int spaceUnits;
}
----

[source,java]
----
import static org.springframework.data.mongodb.core.aggregation.Aggregation.*;

double shippingCosts = 1.2;

TypedAggregation<Product> agg = newAggregation(Product.class,
    project("name", "netPrice")
        .andExpression("(netPrice * (1-discountRate)  + [0]) * (1+taxRate)", shippingCosts).as("salesPrice")
);

AggregationResults<Document> result = mongoTemplate.aggregate(agg, Document.class);
List<Document> resultList = result.getMappedResults();
----

Note that we can also refer to other fields of the document within the SpEL expression.

[[mongo.aggregation.examples.example7]]
===== Aggregation Framework Example 7

This example uses conditional projection. It is derived from the https://docs.mongodb.com/manual/reference/operator/aggregation/cond/[$cond reference documentation].

[source,java]
----
public class InventoryItem {

  @Id int id;
  String item;
  String description;
  int qty;
}

public class InventoryItemProjection {

  @Id int id;
  String item;
  String description;
  int qty;
  int discount
}
----

[source,java]
----
import static org.springframework.data.mongodb.core.aggregation.Aggregation.*;

TypedAggregation<InventoryItem> agg = newAggregation(InventoryItem.class,
  project("item").and("discount")
    .applyCondition(ConditionalOperator.newBuilder().when(Criteria.where("qty").gte(250))
      .then(30)
      .otherwise(20))
    .and(ifNull("description", "Unspecified")).as("description")
);

AggregationResults<InventoryItemProjection> result = mongoTemplate.aggregate(agg, "inventory", InventoryItemProjection.class);
List<InventoryItemProjection> stateStatsList = result.getMappedResults();
----

This one-step aggregation uses a projection operation with the `inventory` collection. We project the `discount` field by using a conditional operation for all inventory items that have a `qty` greater than or equal to `250`. A second conditional projection is performed for the `description` field. We apply the `Unspecified` description to all items that either do not have a `description` field or items that have a `null` description.

As of MongoDB 3.6, it is possible to exclude fields from the projection by using a conditional expression.

.Conditional aggregation projection
====
[source,java]
----
TypedAggregation<Book> agg = Aggregation.newAggregation(Book.class,
  project("title")
    .and(ConditionalOperators.when(ComparisonOperators.valueOf("author.middle")     <1>
        .equalToValue(""))                                                          <2>
        .then("$$REMOVE")                                                           <3>
        .otherwiseValueOf("author.middle")                                          <4>
    )
	.as("author.middle"));
----
<1> If the value of the field `author.middle`
<2> does not contain a value,
<3> then use https://docs.mongodb.com/manual/reference/aggregation-variables/#variable.REMOVE[``$$REMOVE``] to exclude the field.
<4> Otherwise, add the field value of `author.middle`.
====

[[mongo-template.index-and-collections]]
== Index and Collection Management

`MongoTemplate` provides a few methods for managing indexes and collections. These methods are collected into a helper interface called `IndexOperations`. You can access these operations by calling the `indexOps` method and passing in either the collection name or the `java.lang.Class` of your entity (the collection name is derived from the `.class`, either by name or from annotation metadata).

The following listing shows the `IndexOperations` interface:

[source,java]
----
public interface IndexOperations {

  void ensureIndex(IndexDefinition indexDefinition);

  void dropIndex(String name);

  void dropAllIndexes();

  void resetIndexCache();

  List<IndexInfo> getIndexInfo();
}
----

[[mongo-template.index-and-collections.index]]
=== Methods for Creating an Index

You can create an index on a collection to improve query performance by using the MongoTemplate class, as the following example shows:

[source,java]
----
mongoTemplate.indexOps(Person.class).ensureIndex(new Index().on("name",Order.ASCENDING));
----

`ensureIndex` makes sure that an index for the provided IndexDefinition exists for the collection.

You can create standard, geospatial, and text indexes by using the `IndexDefinition`, `GeoSpatialIndex` and `TextIndexDefinition` classes. For example, given the `Venue` class defined in a previous section, you could declare a geospatial query, as the following example shows:

[source,java]
----
mongoTemplate.indexOps(Venue.class).ensureIndex(new GeospatialIndex("location"));
----

NOTE: `Index` and `GeospatialIndex` support configuration of <<mongo.collation,collations>>.

[[mongo-template.index-and-collections.access]]
=== Accessing Index Information

The `IndexOperations` interface has the `getIndexInfo` method that returns a list of `IndexInfo` objects. This list contains all the indexes defined on the collection. The following example defines an index on the `Person` class that has an `age` property:

[source,java]
----
template.indexOps(Person.class).ensureIndex(new Index().on("age", Order.DESCENDING).unique());

List<IndexInfo> indexInfoList = template.indexOps(Person.class).getIndexInfo();

// Contains
// [IndexInfo [fieldSpec={_id=ASCENDING}, name=_id_, unique=false, sparse=false],
//  IndexInfo [fieldSpec={age=DESCENDING}, name=age_-1, unique=true, sparse=false]]
----

[[mongo-template.index-and-collections.collection]]
=== Methods for Working with a Collection

The following example shows how to create a collection:

.Working with collections by using `MongoTemplate`
====
[source,java]
----
MongoCollection<Document> collection = null;
if (!mongoTemplate.getCollectionNames().contains("MyNewCollection")) {
    collection = mongoTemplate.createCollection("MyNewCollection");
}

mongoTemplate.dropCollection("MyNewCollection");
----
====

* *getCollectionNames*: Returns a set of collection names.
* *collectionExists*: Checks to see if a collection with a given name exists.
* *createCollection*: Creates an uncapped collection.
* *dropCollection*: Drops the collection.
* *getCollection*: Gets a collection by name, creating it if it does not exist.

NOTE: Collection creation allows customization with `CollectionOptions` and supports <<mongo.collation,collations>>.

[[mongo-template.commands]]
== Running Commands

You can get at the MongoDB driver's `MongoDatabase.runCommand( )` method by using the `executeCommand(…)` methods on `MongoTemplate`. These methods also perform exception translation into Spring's `DataAccessException` hierarchy.

[[mongo-template.commands.execution]]
=== Methods for running commands

* `Document` *executeCommand* `(Document command)`: Run a MongoDB command.
* `Document` *executeCommand* `(Document command, ReadPreference readPreference)`: Run a MongoDB command with the given nullable MongoDB `ReadPreference`.
* `Document` *executeCommand* `(String jsonCommand)`: Run a MongoDB command expressed as a JSON string.

[[mongodb.mapping-usage.events]]
== Lifecycle Events

The MongoDB mapping framework includes several `org.springframework.context.ApplicationEvent` events that your application can respond to by registering special beans in the `ApplicationContext`. Being based on Spring's `ApplicationContext` event infrastructure enables other products, such as Spring Integration, to easily receive these events, as they are a well known eventing mechanism in Spring-based applications.

To intercept an object before it goes through the conversion process (which turns your domain object into a `org.bson.Document`), you can register a subclass of `AbstractMongoEventListener` that overrides the `onBeforeConvert` method. When the event is dispatched, your listener is called and passed the domain object before it goes into the converter. The following example shows how to do so:

====
[source,java]
----
public class BeforeConvertListener extends AbstractMongoEventListener<Person> {
  @Override
  public void onBeforeConvert(BeforeConvertEvent<Person> event) {
    ... does some auditing manipulation, set timestamps, whatever ...
  }
}
----
====

To intercept an object before it goes into the database, you can register a subclass of `org.springframework.data.mongodb.core.mapping.event.AbstractMongoEventListener` that overrides the `onBeforeSave` method. When the event is dispatched, your listener is called and passed the domain object and the converted `com.mongodb.Document`. The following example shows how to do so:

====
[source,java]
----
public class BeforeSaveListener extends AbstractMongoEventListener<Person> {
  @Override
  public void onBeforeSave(BeforeSaveEvent<Person> event) {
    … change values, delete them, whatever …
  }
}
----
====

Declaring these beans in your Spring ApplicationContext causes them to be invoked whenever the event is dispatched.

The following callback methods are present in `AbstractMappingEventListener`:

* `onBeforeConvert`: Called in `MongoTemplate` `insert`, `insertList`, and `save` operations before the object is converted to a `Document` by a `MongoConverter`.
* `onBeforeSave`: Called in `MongoTemplate` `insert`, `insertList`, and `save` operations *before* inserting or saving the `Document` in the database.
* `onAfterSave`: Called in `MongoTemplate` `insert`, `insertList`, and `save` operations *after* inserting or saving the `Document` in the database.
* `onAfterLoad`: Called in `MongoTemplate` `find`, `findAndRemove`, `findOne`, and `getCollection` methods after the `Document` has been retrieved from the database.
* `onAfterConvert`: Called in `MongoTemplate` `find`, `findAndRemove`, `findOne`, and `getCollection` methods after the `Document` has been retrieved from the database was converted to a POJO.

NOTE: Lifecycle events are only emitted for root level types. Complex types used as properties within a document root are not subject to event publication unless they are document references annotated with `@DBRef`.

WARNING: Lifecycle events depend on an `ApplicationEventMulticaster`, which in case of the `SimpleApplicationEventMulticaster` can be configured with a `TaskExecutor`, and therefore gives no guarantees when an Event is processed.

include::../{spring-data-commons-docs}/entity-callbacks.adoc[leveloffset=+1]
include::./mongo-entity-callbacks.adoc[leveloffset=+2]

[[mongo.exception]]
== Exception Translation

The Spring framework provides exception translation for a wide variety of database and mapping technologies. This has traditionally been for JDBC and JPA. The Spring support for MongoDB extends this feature to the MongoDB Database by providing an implementation of the `org.springframework.dao.support.PersistenceExceptionTranslator` interface.

The motivation behind mapping to Spring's https://docs.spring.io/spring/docs/{springVersion}/spring-framework-reference/data-access.html#dao-exceptions[consistent data access exception hierarchy] is that you are then able to write portable and descriptive exception handling code without resorting to coding against MongoDB error codes. All of Spring's data access exceptions are inherited from the root `DataAccessException` class so that you can be sure to catch all database related exception within a single try-catch block. Note that not all exceptions thrown by the MongoDB driver inherit from the `MongoException` class. The inner exception and message are preserved so that no information is lost.

Some of the mappings performed by the `MongoExceptionTranslator` are `com.mongodb.Network to DataAccessResourceFailureException` and `MongoException` error codes 1003, 12001, 12010, 12011, and 12012 to `InvalidDataAccessApiUsageException`. Look into the implementation for more details on the mapping.

[[mongo.executioncallback]]
== Execution Callbacks

One common design feature of all Spring template classes is that all functionality is routed into one of the template's `execute` callback methods. Doing so helps to ensure that exceptions and any resource management that may be required are performed consistently. While JDBC and JMS need this feature much more than MongoDB does, it still offers a single spot for exception translation and logging to occur. Consequently, using these `execute` callbacks is the preferred way to access the MongoDB driver's `MongoDatabase` and `MongoCollection` objects to perform uncommon operations that were not exposed as methods on `MongoTemplate`.

The following list describes the `execute` callback methods.

* `<T> T` *execute* `(Class<?> entityClass, CollectionCallback<T> action)`: Runs the given `CollectionCallback` for the entity collection of the specified class.

* `<T> T` *execute* `(String collectionName, CollectionCallback<T> action)`: Runs the given `CollectionCallback` on the collection of the given name.

* `<T> T` *execute* `(DbCallback<T> action)`: Runs a DbCallback, translating any exceptions as necessary. Spring Data MongoDB provides support for the Aggregation Framework introduced to MongoDB in version 2.2.

* `<T> T` *execute* `(String collectionName, DbCallback<T> action)`: Runs a `DbCallback` on the collection of the given name translating any exceptions as necessary.

* `<T> T` *executeInSession* `(DbCallback<T> action)`: Runs the given `DbCallback` within the same connection to the database so as to ensure consistency in a write-heavy environment where you may read the data that you wrote.

The following example uses the `CollectionCallback` to return information about an index:

[source,java]
----
boolean hasIndex = template.execute("geolocation", new CollectionCallbackBoolean>() {
  public Boolean doInCollection(Venue.class, DBCollection collection) throws MongoException, DataAccessException {
    List<Document> indexes = collection.getIndexInfo();
    for (Document document : indexes) {
      if ("location_2d".equals(document.get("name"))) {
        return true;
      }
    }
    return false;
  }
});
----

[[gridfs]]
== GridFS Support

MongoDB supports storing binary files inside its filesystem, GridFS. Spring Data MongoDB provides a `GridFsOperations` interface as well as the corresponding implementation, `GridFsTemplate`, to let you interact with the filesystem. You can set up a `GridFsTemplate` instance by handing it a `MongoDatabaseFactory` as well as a `MongoConverter`, as the following example shows:

.JavaConfig setup for a GridFsTemplate
====
[source,java]
----
class GridFsConfiguration extends AbstractMongoClientConfiguration {

  // … further configuration omitted

  @Bean
  public GridFsTemplate gridFsTemplate() {
    return new GridFsTemplate(mongoDbFactory(), mappingMongoConverter());
  }
}
----
====

The corresponding XML configuration follows:

.XML configuration for a GridFsTemplate
====
[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns:mongo="http://www.springframework.org/schema/data/mongo"
  xsi:schemaLocation="http://www.springframework.org/schema/data/mongo
                      https://www.springframework.org/schema/data/mongo/spring-mongo.xsd
                      http://www.springframework.org/schema/beans
                      https://www.springframework.org/schema/beans/spring-beans.xsd">

  <mongo:db-factory id="mongoDbFactory" dbname="database" />
  <mongo:mapping-converter id="converter" />

  <bean class="org.springframework.data.mongodb.gridfs.GridFsTemplate">
    <constructor-arg ref="mongoDbFactory" />
    <constructor-arg ref="converter" />
  </bean>

</beans>
----
====

The template can now be injected and used to perform storage and retrieval operations, as the following example shows:

.Using GridFsTemplate to store files
====
[source,java]
----
class GridFsClient {

  @Autowired
  GridFsOperations operations;

  @Test
  public void storeFileToGridFs() {

    FileMetadata metadata = new FileMetadata();
    // populate metadata
    Resource file = … // lookup File or Resource

    operations.store(file.getInputStream(), "filename.txt", metadata);
  }
}
----
====

The `store(…)` operations take an `InputStream`, a filename, and (optionally) metadata information about the file to store. The metadata can be an arbitrary object, which will be marshaled by the `MongoConverter` configured with the `GridFsTemplate`. Alternatively, you can also provide a `Document`.

You can read files from the filesystem through either the `find(…)` or the `getResources(…)` methods. Let's have a look at the `find(…)` methods first. You can either find a single file or multiple files that match a `Query`. You can use the `GridFsCriteria` helper class to define queries. It provides static factory methods to encapsulate default metadata fields (such as `whereFilename()` and `whereContentType()`) or a custom one through `whereMetaData()`. The following example shows how to use `GridFsTemplate` to query for files:

.Using GridFsTemplate to query for files
====
[source,java]
----
class GridFsClient {

  @Autowired
  GridFsOperations operations;

  @Test
  public void findFilesInGridFs() {
    GridFSFindIterable result = operations.find(query(whereFilename().is("filename.txt")))
  }
}
----
====

NOTE: Currently, MongoDB does not support defining sort criteria when retrieving files from GridFS. For this reason, any sort criteria defined on the `Query` instance handed into the `find(…)` method are disregarded.

The other option to read files from the GridFs is to use the methods introduced by the `ResourcePatternResolver` interface. They allow handing an Ant path into the method and can thus retrieve files matching the given pattern. The following example shows how to use `GridFsTemplate` to read files:

.Using GridFsTemplate to read files
====
[source,java]
----
class GridFsClient {

  @Autowired
  GridFsOperations operations;

  @Test
  public void readFilesFromGridFs() {
    GridFsResources[] txtFiles = operations.getResources("*.txt");
  }
}
----
====

`GridFsOperations` extends `ResourcePatternResolver` and lets the `GridFsTemplate` (for example) to be plugged into an `ApplicationContext` to read Spring Config files from MongoDB database.

include::tailable-cursors.adoc[]
include::change-streams.adoc[]
