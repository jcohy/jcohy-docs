[[redis.streams]]
= Redis Streams

Redis Streams 以更抽象的方式模拟日志数据结构. 就像一个日志文件,通常实现为以只附加模式打开的文件,从一开始就在随机位置或通过流式传输新消息来使用日志.

NOTE:  https://redis.io/topics/streams-intro[Redis 参考文档] 中获取有关 Redis Stream 的文档.

Redis Streams 可以大致分为两个功能区域:

* 追加记录
* 消费记录

尽管此模式与发布/订阅有相似之处,但主要区别在于消息的持久性及其使用方式.

尽管发布/订阅依赖于广播瞬态消息(即,如果您不收听,则会错过一条消息),但 Redis Stream 使用一种持久的,仅追加的数据类型,该类型将保留消息,直到流被修剪为止. 消费方面的另一个区别是<<pubsub, Pub/Sub>> 注册了服务器端订阅. Redis Stream 需要活动轮询时,
Redis 将到达的消息推送到客户端.

`org.springframework.data.redis.connection` 和 `org.springframework.data.redis.stream` 包提供 Redis Streams 的核心功能.

NOTE: Redis Stream 支持当前仅可通过 <<redis:connectors:lettuce, Lettuce 客户端>> 获得,因为  <<redis:connectors:jedis, Jedis>> 尚不支持.

[[redis.streams.send]]
== 追加

要发送记录,可以与其他操作一起使用底层 `RedisConnection` 或高级 `StreamOperations`. 这两个实体都提供 `add` (`xAdd`) 方法,该方法接受记录和目标流作为参数.
尽管 `RedisConnection` 需要原始数据(字节数组),但 `StreamOperations` 允许将任意对象作为记录传递,如以下示例所示:

[source,java]
----
// append message through connection 
RedisConnection con = …
byte[] stream = …
ByteRecord record = StreamRecords.rawBytes(…).withStreamKey(stream);
con.xAdd(record);

// append message through RedisTemplate
RedisTemplate template = …
StringRecord record = StreamRecords.string(…).withStreamKey("my-stream");
template.streamOps().add(record);
----

Stream 记录携带 `Map`,键值元组作为其有效负载. 将记录追加到流将返回 RecordId,该 RecordId 可用作进一步参考.

[[redis.streams.receive]]
== 消费

在消费方面,可以消费一个或多个流. Redis 流提供读取命令,该命令允许从已知流内容内的任意位置(流访问之外)的任意位置(随机访问)使用流,以消耗新的流记录.

在低层,`RedisConnection` 提供了 `xRead` 和 `xReadGroup` 方法,它们分别映射 Redis 命令以在使用者组中进行读取和读取. 请注意,可以将多个流用作参数.

NOTE: Redis 中的订阅命令可能被阻塞. 也就是说,在连接上调用 `xRead` 会导致当前线程在开始等待消息并阻塞. 仅当读取命令超时或收到消息时才释放线程.

要使用流消息,可以在应用程序代码中轮询消息,或者通过消息监听器容器使用两种 <<redis.streams.receive.containers>> 之一,即命令式或响应式. 每当有新记录到达时,容器都会通知应用程序代码.

[[redis.streams.receive.synchronous]]
=== 同步接收

虽然消费流通常与异步处理相关联,但是可以同步消费消息. 重载的  `StreamOperations.read(…)` 方法提供了此功能. 在同步接收期间,调用线程可能会阻塞,直到消息可用为止. `StreamReadOptions.block` 属性指定接收者在放弃等待消息之前应该等待多长时间.

[source,java]
----
// Read message through RedisTemplate
RedisTemplate template = …

List<MapRecord<K, HK, HV>> messages = template.streamOps().read(StreamReadOptions.empty().count(2),
				StreamOffset.latest("my-stream"));

List<MapRecord<K, HK, HV>> messages = template.streamOps().read(Consumer.from("my-group", "my-consumer"),
				StreamReadOptions.empty().count(2),
				StreamOffset.create("my-stream", ReadOffset.lastConsumed()))
----

[[redis.streams.receive.containers]]
=== 通过消息监听器容器进行异步接收

由于其阻塞性质,低级别轮询没有吸引力,因为它需要每个单个使用者进行连接和线程管理. 为了减轻这个问题,Spring Data 提供了消息监听器,它可以完成所有繁重的工作. 如果您熟悉 EJB 和 JMS,则应该熟悉这些概念,因为它被设计为尽可能接近 Spring Framework 及其消息驱动的POJO(MDP)的支持.

Spring Data 附带了两种针对所用编程模型的实现:

* `StreamMessageListenerContainer` 充当命令式编程模型的消息监听器容器. 它用于消耗Redis流中的记录并驱动注入其中的 `StreamListener` 实例.
* `StreamReceiver` 提供了消息监听器的响应式变体. 它用于将来自 Redis 流的消息作为潜在的无限流使用,并通过 `Flux` 发出流消息.

`StreamMessageListenerContainer` 和 `StreamReceiver` 负责消息接收的所有线程,并分派到监听器中进行处理. 消息监听器容器/接收器是MDP与消息传递提供程序之间的中介,并负责注册接收消息,资源获取和释放,异常转换等.
这使您作为应用程序开发人员可以编写与接收消息(并对消息做出响应)相关的(可能很复杂的)业务逻辑,并将样板 Redis 基础结构问题委托给框架.

这两个容器都允许更改运行时配置,因此您可以在应用程序运行时添加或删除订阅,而无需重新启动. 此外,容器使用延迟订阅方法,仅在需要时才使用 `RedisConnection`. 如果所有监听器都未订阅,它将自动执行清除,然后释放线程.

==== `StreamMessageListenerContainer`

流驱动POJO(SDP)以类似于EJB世界中的消息驱动Bean(MDB)的方式充当流消息的接收者. SDP 的一个限制是它必须实现 `org.springframework.data.redis.stream.StreamListener` 接口. 还请注意,在POJO在多个线程上接收消息的情况下,确保您的实现是线程安全的很重要.

[source,java]
----
class ExampleStreamListener implements StreamListener<String, MapRecord<String, String, String>> {

	@Override
	public void onMessage(MapRecord<String, String, String> message) {

		System.out.println("MessageId: " + message.getId());
		System.out.println("Stream: " + message.getStream());
		System.out.println("Body: " + message.getValue());
	}
}
----

`StreamListener` 表示一个功能接口,因此可以使用其 Lambda 形式重写实现:

[source,java]
----
message -> {

    System.out.println("MessageId: " + message.getId());
    System.out.println("Stream: " + message.getStream());
    System.out.println("Body: " + message.getValue());
};
----

一旦实现了 `StreamListener`,就可以创建一个消息监听器容器并注册订阅了:

[source,java]
----
RedisConnectionFactory connectionFactory = …
StreamListener<String, MapRecord<String, String, String>> streamListener = …
 
StreamMessageListenerContainerOptions<String, MapRecord<String, String, String>> containerOptions = StreamMessageListenerContainerOptions
			.builder().pollTimeout(Duration.ofMillis(100)).build();
			
StreamMessageListenerContainer<String, MapRecord<String, String, String>> container = StreamMessageListenerContainer.create(connectionFactory,
				containerOptions);
				
Subscription subscription = container.receive(StreamOffset.fromStart("my-stream"), streamListener);
----

请参阅各种消息监听器容器的 Javadoc,以获取每个实现所支持功能的完整说明.

==== Reactive `StreamReceiver`

流式数据源的 Reactive consumption 通常通过 `Flux` 的事件或消息发生. 响应接收器实现由 `StreamReceiver` 和重载的 `receive(…)` 消息提供. 与 `StreamMessageListenerContainer` 相比,被动方法需要更少的基础结构资源,例如线程,因为它利用了驱动程序提供的线程资源. 接收流是 ``StreamMessage`` 的需求驱动的发布者:

[source,java]
----
Flux<MapRecord<String, String, String>> messages = …

return messages.doOnNext(it -> {
    System.out.println("MessageId: " + message.getId());
    System.out.println("Stream: " + message.getStream());
    System.out.println("Body: " + message.getValue());
});
----

现在我们需要创建 `StreamReceiver` 并注册一个订阅以使用流消息:

[source,java]
----
ReactiveRedisConnectionFactory connectionFactory = …

StreamReceiverOptions<String, MapRecord<String, String, String>> options = StreamReceiverOptions.builder().pollTimeout(Duration.ofMillis(100))
				.build();
StreamReceiver<String, MapRecord<String, String, String>> receiver = StreamReceiver.create(connectionFactory, options);
				
Flux<MapRecord<String, String, String>> messages = receiver.receive(StreamOffset.fromStart("my-stream"));
----

请参阅各种消息监听器容器的 Javadoc,以获取每个实现所支持功能的完整说明.

NOTE: 需求驱动的消耗使用背压信号来激活和停用轮询. 如果满足需求,则 `StreamReceiver` 订阅将暂停轮询,直到订阅者发出进一步的请求. 根据 `ReadOffset` 策略,这可能导致消息被跳过.

[[redis.streams.acknowledge]]
=== `Acknowledge` 策略

当您通过 `Consumer Group` 阅读邮件时,服务器将记住已传递给定邮件,并将其添加到"待处理条目列表”(PEL)中. 已发送但尚未确认的邮件列表.
消息必须通过 `StreamOperations.acknowledge` 进行确认,以便从待处理条目列表中删除,如下面的代码片段所示.

====
[source,java]
----
StreamMessageListenerContainer<String, MapRecord<String, String, String>> container = ...

container.receive(Consumer.from("my-group", "my-consumer"), <1>
	StreamOffset.create("my-stream", ReadOffset.lastConsumed()),
    msg -> {

	    // ...
	    redisTemplate.opsForStream().acknowledge("my-group", msg); <2>
    });
----
<1> 从 _my-group_ 组读取为 _my-consumer_. 收到的消息不被确认.
<2> 处理后确认消息.
====

TIP: 要在接收时自动确认消息,请使用 `receiveAutoAck` 而不是 `receive`.

[[redis.streams.receive.readoffset]]
=== `ReadOffset` 策略

流读取操作接受读取偏移量规范以从给定偏移量开始消耗消息. `ReadOffset` 表示读取偏移量规范. Redis支持三种偏移量,具体取决于您是独立使用流还是在使用者组中使用流:

* `ReadOffset.latest()` – 阅读最新消息.
* `ReadOffset.from(…)` – 在特定消息ID之后阅读.
* `ReadOffset.lastConsumed()` – 在最后消耗的消息ID之后读取(仅针对消费者组).

在基于消息容器的使用情况下,我们在使用消息时需要提高(或增加)读取偏移量. 前进取决于请求的 `ReadOffset` 和消费模式(有/无消费组). 以下矩阵说明了容器如何提高 `ReadOffset`:

.ReadOffset Advancing
[options="header,footer,autowidth"]
|===
| Read offset         | Standalone          | Consumer Group
| Latest              | Read latest message | Read latest message
| Specific Message Id | Use last seen message as the next MessageId | Use last seen message as the next MessageId
| Last Consumed       | Use last seen message as the next MessageId | Last consumed message as per consumer group
|===

从特定消息ID和最后使用的消息读取可以被视为安全操作,可确保消耗附加到流中的所有消息. 使用最新消息进行读取可以跳过在轮询操作处于停滞时间状态时添加到流中的消息. 轮询会引入一个停滞时间,在该停滞时间内消息可以在各个轮询命令之间到达. 流消耗不是线性连续读取,
而是分成重复的 `XREAD` 调用.

[[redis.streams.receive.serialization]]
=== 序列化

发送到流的任何记录都需要序列化为其二进制格式. 由于流与哈希数据结构非常接近,因此流键,字段名称和值使用在 `RedisTemplate` 上配置的相应序列化器.

.Stream Serialization
[options="header,footer,autowidth"]
|===
| Stream Property  | Serializer          | Description
| key              | keySerializer       | used for `Record#getStream()`
| field            | hashKeySerializer   | used for each map key in the payload
| value            | hashValueSerializer | used for each map value in the payload
|===

请确保查看使用中的Redis  ``RedisSerializer``,并注意,如果您决定不使用任何序列化器,则需要确保这些值已经是二进制的.

[[redis.streams.hashing]]
=== Object Mapping

==== 简单的值

`StreamOperations` 允许通过 `ObjectRecord` 将简单值直接附加到流,而不必将这些值放入 `Map` 结构中. 然后将该值分配给有效负载字段,并在读回该值时可以将其提取.

[source,java]
----
ObjectRecord<String, String> record = StreamRecords.newRecord()
    .in("my-stream")
    .ofObject("my-value");

redisTemplate()
    .opsForStream()
    .add(record); <1>

List<ObjectRecord<String, String>> records = redisTemplate()
    .opsForStream()
    .read(String.class, StreamOffset.fromStart("my-stream"));
----
<1> XADD my-stream * "_class" "java.lang.String" "_raw" "my-value"

``ObjectRecord``s 与所有其他记录通过相同的序列化过程,因此 Record 也可以使用返回 `MapRecord` 的无类型读取操作获得.

==== 复杂的值

可以通过3种方式将复杂的值添加到流中:

* 使用转换为简单值. 字符串JSON表示形式.
* 用合适的 `RedisSerializer` 序列化该值.
* 使用 `HashMapper` 将值转换为适合于序列化的 `Map`.

第一个变体是最直接的变体,但忽略了流结构提供的字段值功能,但流中的值仍可供其他使用者读取. 第二个选项具有与第一个选项相同的好处,但是可能会导致非常特殊的使用方限制,因为所有使用方都必须实现完全相同的序列化机制. `HashMapper` 方法是一种更复杂的方法,它使用了 Steam 哈希结构,但是却使源代码变得平坦. 只要选择了合适的序列化器组合,其他使用者仍然可以读取记录.

NOTE: `HashMappers` 将有效负载转换为具有特定类型的Map. 确保使用能够(反)序列化哈希的哈希键和哈希值序列化程序.

[source,java]
----
ObjectRecord<String, User> record = StreamRecords.newRecord()
    .in("user-logon")
    .ofObject(new User("night", "angel"));

redisTemplate()
    .opsForStream()
    .add(record); <1>

List<ObjectRecord<String, User>> records = redisTemplate()
    .opsForStream()
    .read(User.class, StreamOffset.fromStart("user-logon"));
----
<1> XADD user-logon * "_class" "com.example.User" "firstname" "night" "lastname" "angel"

默认情况下,`StreamOperations` 使用  <<redis.repositories.mapping, ObjectHashMapper>>. 获取 `StreamOperations` 时,可以提供适合您要求的 `HashMapper`.

[source,java]
----
redisTemplate()
    .opsForStream(new Jackson2HashMapper(true))
    .add(record); <1>
----
<1> XADD user-logon * "firstname" "night" "@class" "com.example.User" "lastname" "angel"

[NOTE]
====
`StreamMessageListenerContainer` 可能并不知道 domain 类型上使用的任何 `@TypeAlias`, 因为需要通过 `MappingContext` 进行解析. 确保使用 `initialEntitySet` 初始化 `RedisMappingContext`.

[source,java]
----
@Bean
RedisMappingContext redisMappingContext() {
    RedisMappingContext ctx = new RedisMappingContext();
    ctx.setInitialEntitySet(Collections.singleton(Person.class));
    return ctx;
}

@Bean
RedisConverter redisConverter(RedisMappingContext mappingContext) {
    return new MappingRedisConverter(mappingContext);
}

@Bean
ObjectHashMapper hashMapper(RedisConverter converter) {
    return new ObjectHashMapper(converter);
}

@Bean
StreamMessageListenerContainer streamMessageListenerContainer(RedisConnectionFactory connectionFactory, ObjectHashMapper hashMapper) {
    StreamMessageListenerContainerOptions<String, ObjectRecord<String, Object>> options = StreamMessageListenerContainerOptions.builder()
            .objectMapper(hashMapper)
            .build();

    return StreamMessageListenerContainer.create(connectionFactory, options);
}
----
====

